{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Attention Graph Pooling (SAGP) reproducing code\n",
    "Author: 'Yeongtak Oh'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (Original) highly-cited by 'https://github.com/inyeoplee77/SAGPool'\n",
    "* torch-geometric : 'https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.pool.SAGPooling'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric import utils\n",
    "from networks import  Net\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "import easydict\n",
    "\n",
    "# dataset selection: AIDS, DD, PROTEINS, NCI1\n",
    "args = easydict.EasyDict({\"seed\": 777, \n",
    "                          \"batch_size\": 128, \n",
    "                          \"lr\": 0.0005, \n",
    "                          \"weight_decay\": 0.0001, \n",
    "                          \"nhid\": 128, \n",
    "                          \"pooling_ratio\": 0.5, \n",
    "                          \"dropout_ratio\": 0.5, \n",
    "                          \"dataset\": 'NCI1', \n",
    "                          \"epochs\": 100000, \n",
    "                          \"patience\": 50, \n",
    "                          \"pooling_layer_type\":'GCNConv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ls11-www.cs.tu-dortmund.de/people/morris/graphkerneldatasets/NCI1.zip\n",
      "Extracting data/NCI1/NCI1/NCI1.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# device setting\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    args.device = 'cuda:0'\n",
    "    \n",
    "# data load\n",
    "dataset = TUDataset(os.path.join('data',args.dataset),name=args.dataset)\n",
    "args.num_classes = dataset.num_classes\n",
    "args.num_features = dataset.num_features\n",
    "num_training = int(len(dataset)*0.8)\n",
    "num_val = int(len(dataset)*0.1)\n",
    "num_test = len(dataset) - (num_training+num_val)\n",
    "training_set,validation_set,test_set = random_split(dataset,[num_training,num_val,num_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== epoch 0 ======\n",
      "Training loss:0.698\n",
      "Training loss:0.693\n",
      "Training loss:0.693\n",
      "Training loss:0.692\n",
      "Training loss:0.694\n",
      "Training loss:0.692\n",
      "Training loss:0.694\n",
      "Training loss:0.696\n",
      "Training loss:0.692\n",
      "Training loss:0.690\n",
      "Training loss:0.695\n",
      "Training loss:0.693\n",
      "Training loss:0.693\n",
      "Training loss:0.693\n",
      "Training loss:0.693\n",
      "Training loss:0.694\n",
      "Training loss:0.693\n",
      "Training loss:0.695\n",
      "Training loss:0.692\n",
      "Training loss:0.693\n",
      "Training loss:0.693\n",
      "Training loss:0.691\n",
      "Training loss:0.693\n",
      "Training loss:0.691\n",
      "Training loss:0.693\n",
      "Training loss:0.693\n",
      "Validation loss:0.693\taccuracy:0.479\n",
      "Model saved at epoch0\n",
      "\n",
      "\n",
      "====== epoch 1 ======\n",
      "Training loss:0.692\n",
      "Training loss:0.692\n",
      "Training loss:0.695\n",
      "Training loss:0.691\n",
      "Training loss:0.692\n",
      "Training loss:0.694\n",
      "Training loss:0.689\n",
      "Training loss:0.694\n",
      "Training loss:0.694\n",
      "Training loss:0.692\n",
      "Training loss:0.693\n",
      "Training loss:0.693\n",
      "Training loss:0.693\n",
      "Training loss:0.692\n",
      "Training loss:0.693\n",
      "Training loss:0.695\n",
      "Training loss:0.694\n",
      "Training loss:0.690\n",
      "Training loss:0.694\n",
      "Training loss:0.693\n",
      "Training loss:0.694\n",
      "Training loss:0.691\n",
      "Training loss:0.693\n",
      "Training loss:0.694\n",
      "Training loss:0.692\n",
      "Training loss:0.692\n",
      "Validation loss:0.692\taccuracy:0.499\n",
      "Model saved at epoch1\n",
      "\n",
      "\n",
      "====== epoch 2 ======\n",
      "Training loss:0.690\n",
      "Training loss:0.690\n",
      "Training loss:0.692\n",
      "Training loss:0.693\n",
      "Training loss:0.692\n",
      "Training loss:0.693\n",
      "Training loss:0.690\n",
      "Training loss:0.693\n",
      "Training loss:0.690\n",
      "Training loss:0.691\n",
      "Training loss:0.692\n",
      "Training loss:0.693\n",
      "Training loss:0.691\n",
      "Training loss:0.694\n",
      "Training loss:0.691\n",
      "Training loss:0.689\n",
      "Training loss:0.690\n",
      "Training loss:0.689\n",
      "Training loss:0.691\n",
      "Training loss:0.687\n",
      "Training loss:0.688\n",
      "Training loss:0.695\n",
      "Training loss:0.690\n",
      "Training loss:0.690\n",
      "Training loss:0.690\n",
      "Training loss:0.686\n",
      "Validation loss:0.686\taccuracy:0.560\n",
      "Model saved at epoch2\n",
      "\n",
      "\n",
      "====== epoch 3 ======\n",
      "Training loss:0.686\n",
      "Training loss:0.687\n",
      "Training loss:0.691\n",
      "Training loss:0.681\n",
      "Training loss:0.688\n",
      "Training loss:0.682\n",
      "Training loss:0.690\n",
      "Training loss:0.684\n",
      "Training loss:0.679\n",
      "Training loss:0.684\n",
      "Training loss:0.679\n",
      "Training loss:0.684\n",
      "Training loss:0.681\n",
      "Training loss:0.688\n",
      "Training loss:0.680\n",
      "Training loss:0.675\n",
      "Training loss:0.686\n",
      "Training loss:0.686\n",
      "Training loss:0.681\n",
      "Training loss:0.697\n",
      "Training loss:0.688\n",
      "Training loss:0.684\n",
      "Training loss:0.683\n",
      "Training loss:0.672\n",
      "Training loss:0.679\n",
      "Training loss:0.711\n",
      "Validation loss:0.664\taccuracy:0.613\n",
      "Model saved at epoch3\n",
      "\n",
      "\n",
      "====== epoch 4 ======\n",
      "Training loss:0.667\n",
      "Training loss:0.687\n",
      "Training loss:0.673\n",
      "Training loss:0.680\n",
      "Training loss:0.672\n",
      "Training loss:0.667\n",
      "Training loss:0.673\n",
      "Training loss:0.685\n",
      "Training loss:0.660\n",
      "Training loss:0.676\n",
      "Training loss:0.678\n",
      "Training loss:0.678\n",
      "Training loss:0.690\n",
      "Training loss:0.658\n",
      "Training loss:0.676\n",
      "Training loss:0.686\n",
      "Training loss:0.698\n",
      "Training loss:0.649\n",
      "Training loss:0.640\n",
      "Training loss:0.681\n",
      "Training loss:0.699\n",
      "Training loss:0.692\n",
      "Training loss:0.676\n",
      "Training loss:0.719\n",
      "Training loss:0.637\n",
      "Training loss:0.639\n",
      "Validation loss:0.651\taccuracy:0.625\n",
      "Model saved at epoch4\n",
      "\n",
      "\n",
      "====== epoch 5 ======\n",
      "Training loss:0.640\n",
      "Training loss:0.680\n",
      "Training loss:0.672\n",
      "Training loss:0.685\n",
      "Training loss:0.642\n",
      "Training loss:0.699\n",
      "Training loss:0.653\n",
      "Training loss:0.668\n",
      "Training loss:0.720\n",
      "Training loss:0.654\n",
      "Training loss:0.707\n",
      "Training loss:0.633\n",
      "Training loss:0.663\n",
      "Training loss:0.668\n",
      "Training loss:0.671\n",
      "Training loss:0.670\n",
      "Training loss:0.672\n",
      "Training loss:0.652\n",
      "Training loss:0.669\n",
      "Training loss:0.657\n",
      "Training loss:0.675\n",
      "Training loss:0.680\n",
      "Training loss:0.674\n",
      "Training loss:0.677\n",
      "Training loss:0.695\n",
      "Training loss:0.655\n",
      "Validation loss:0.649\taccuracy:0.625\n",
      "Model saved at epoch5\n",
      "\n",
      "\n",
      "====== epoch 6 ======\n",
      "Training loss:0.670\n",
      "Training loss:0.670\n",
      "Training loss:0.678\n",
      "Training loss:0.650\n",
      "Training loss:0.637\n",
      "Training loss:0.700\n",
      "Training loss:0.673\n",
      "Training loss:0.666\n",
      "Training loss:0.661\n",
      "Training loss:0.672\n",
      "Training loss:0.710\n",
      "Training loss:0.642\n",
      "Training loss:0.646\n",
      "Training loss:0.665\n",
      "Training loss:0.623\n",
      "Training loss:0.688\n",
      "Training loss:0.657\n",
      "Training loss:0.687\n",
      "Training loss:0.703\n",
      "Training loss:0.657\n",
      "Training loss:0.709\n",
      "Training loss:0.678\n",
      "Training loss:0.645\n",
      "Training loss:0.658\n",
      "Training loss:0.682\n",
      "Training loss:0.633\n",
      "Validation loss:0.649\taccuracy:0.628\n",
      "\n",
      "\n",
      "====== epoch 7 ======\n",
      "Training loss:0.698\n",
      "Training loss:0.674\n",
      "Training loss:0.717\n",
      "Training loss:0.661\n",
      "Training loss:0.659\n",
      "Training loss:0.652\n",
      "Training loss:0.653\n",
      "Training loss:0.656\n",
      "Training loss:0.666\n",
      "Training loss:0.653\n",
      "Training loss:0.656\n",
      "Training loss:0.632\n",
      "Training loss:0.742\n",
      "Training loss:0.627\n",
      "Training loss:0.673\n",
      "Training loss:0.685\n",
      "Training loss:0.666\n",
      "Training loss:0.661\n",
      "Training loss:0.656\n",
      "Training loss:0.666\n",
      "Training loss:0.646\n",
      "Training loss:0.664\n",
      "Training loss:0.651\n",
      "Training loss:0.655\n",
      "Training loss:0.668\n",
      "Training loss:0.674\n",
      "Validation loss:0.654\taccuracy:0.601\n",
      "\n",
      "\n",
      "====== epoch 8 ======\n",
      "Training loss:0.661\n",
      "Training loss:0.665\n",
      "Training loss:0.663\n",
      "Training loss:0.703\n",
      "Training loss:0.672\n",
      "Training loss:0.710\n",
      "Training loss:0.642\n",
      "Training loss:0.658\n",
      "Training loss:0.673\n",
      "Training loss:0.653\n",
      "Training loss:0.682\n",
      "Training loss:0.681\n",
      "Training loss:0.656\n",
      "Training loss:0.679\n",
      "Training loss:0.680\n",
      "Training loss:0.686\n",
      "Training loss:0.658\n",
      "Training loss:0.664\n",
      "Training loss:0.643\n",
      "Training loss:0.667\n",
      "Training loss:0.646\n",
      "Training loss:0.660\n",
      "Training loss:0.669\n",
      "Training loss:0.684\n",
      "Training loss:0.662\n",
      "Training loss:0.644\n",
      "Validation loss:0.642\taccuracy:0.633\n",
      "Model saved at epoch8\n",
      "\n",
      "\n",
      "====== epoch 9 ======\n",
      "Training loss:0.647\n",
      "Training loss:0.675\n",
      "Training loss:0.613\n",
      "Training loss:0.730\n",
      "Training loss:0.667\n",
      "Training loss:0.667\n",
      "Training loss:0.626\n",
      "Training loss:0.694\n",
      "Training loss:0.654\n",
      "Training loss:0.646\n",
      "Training loss:0.659\n",
      "Training loss:0.657\n",
      "Training loss:0.655\n",
      "Training loss:0.686\n",
      "Training loss:0.627\n",
      "Training loss:0.663\n",
      "Training loss:0.677\n",
      "Training loss:0.611\n",
      "Training loss:0.684\n",
      "Training loss:0.688\n",
      "Training loss:0.645\n",
      "Training loss:0.687\n",
      "Training loss:0.667\n",
      "Training loss:0.625\n",
      "Training loss:0.655\n",
      "Training loss:0.662\n",
      "Validation loss:0.634\taccuracy:0.657\n",
      "Model saved at epoch9\n",
      "\n",
      "\n",
      "====== epoch 10 ======\n",
      "Training loss:0.651\n",
      "Training loss:0.658\n",
      "Training loss:0.650\n",
      "Training loss:0.701\n",
      "Training loss:0.653\n",
      "Training loss:0.626\n",
      "Training loss:0.681\n",
      "Training loss:0.669\n",
      "Training loss:0.654\n",
      "Training loss:0.654\n",
      "Training loss:0.666\n",
      "Training loss:0.630\n",
      "Training loss:0.642\n",
      "Training loss:0.669\n",
      "Training loss:0.674\n",
      "Training loss:0.646\n",
      "Training loss:0.640\n",
      "Training loss:0.664\n",
      "Training loss:0.652\n",
      "Training loss:0.642\n",
      "Training loss:0.629\n",
      "Training loss:0.682\n",
      "Training loss:0.654\n",
      "Training loss:0.656\n",
      "Training loss:0.656\n",
      "Training loss:0.645\n",
      "Validation loss:0.629\taccuracy:0.647\n",
      "Model saved at epoch10\n",
      "\n",
      "\n",
      "====== epoch 11 ======\n",
      "Training loss:0.609\n",
      "Training loss:0.674\n",
      "Training loss:0.679\n",
      "Training loss:0.641\n",
      "Training loss:0.632\n",
      "Training loss:0.654\n",
      "Training loss:0.643\n",
      "Training loss:0.622\n",
      "Training loss:0.668\n",
      "Training loss:0.626\n",
      "Training loss:0.703\n",
      "Training loss:0.643\n",
      "Training loss:0.646\n",
      "Training loss:0.657\n",
      "Training loss:0.658\n",
      "Training loss:0.674\n",
      "Training loss:0.680\n",
      "Training loss:0.646\n",
      "Training loss:0.628\n",
      "Training loss:0.646\n",
      "Training loss:0.654\n",
      "Training loss:0.638\n",
      "Training loss:0.642\n",
      "Training loss:0.669\n",
      "Training loss:0.650\n",
      "Training loss:0.637\n",
      "Validation loss:0.628\taccuracy:0.655\n",
      "Model saved at epoch11\n",
      "\n",
      "\n",
      "====== epoch 12 ======\n",
      "Training loss:0.639\n",
      "Training loss:0.633\n",
      "Training loss:0.641\n",
      "Training loss:0.671\n",
      "Training loss:0.690\n",
      "Training loss:0.645\n",
      "Training loss:0.635\n",
      "Training loss:0.638\n",
      "Training loss:0.625\n",
      "Training loss:0.667\n",
      "Training loss:0.668\n",
      "Training loss:0.630\n",
      "Training loss:0.662\n",
      "Training loss:0.679\n",
      "Training loss:0.597\n",
      "Training loss:0.638\n",
      "Training loss:0.654\n",
      "Training loss:0.624\n",
      "Training loss:0.622\n",
      "Training loss:0.626\n",
      "Training loss:0.629\n",
      "Training loss:0.647\n",
      "Training loss:0.700\n",
      "Training loss:0.632\n",
      "Training loss:0.678\n",
      "Training loss:0.648\n",
      "Validation loss:0.624\taccuracy:0.650\n",
      "Model saved at epoch12\n",
      "\n",
      "\n",
      "====== epoch 13 ======\n",
      "Training loss:0.619\n",
      "Training loss:0.637\n",
      "Training loss:0.593\n",
      "Training loss:0.628\n",
      "Training loss:0.656\n",
      "Training loss:0.699\n",
      "Training loss:0.672\n",
      "Training loss:0.680\n",
      "Training loss:0.600\n",
      "Training loss:0.635\n",
      "Training loss:0.604\n",
      "Training loss:0.619\n",
      "Training loss:0.670\n",
      "Training loss:0.641\n",
      "Training loss:0.652\n",
      "Training loss:0.633\n",
      "Training loss:0.678\n",
      "Training loss:0.637\n",
      "Training loss:0.635\n",
      "Training loss:0.664\n",
      "Training loss:0.666\n",
      "Training loss:0.667\n",
      "Training loss:0.629\n",
      "Training loss:0.637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.637\n",
      "Training loss:0.637\n",
      "Validation loss:0.625\taccuracy:0.664\n",
      "\n",
      "\n",
      "====== epoch 14 ======\n",
      "Training loss:0.694\n",
      "Training loss:0.623\n",
      "Training loss:0.632\n",
      "Training loss:0.595\n",
      "Training loss:0.634\n",
      "Training loss:0.648\n",
      "Training loss:0.653\n",
      "Training loss:0.681\n",
      "Training loss:0.643\n",
      "Training loss:0.626\n",
      "Training loss:0.631\n",
      "Training loss:0.645\n",
      "Training loss:0.656\n",
      "Training loss:0.677\n",
      "Training loss:0.631\n",
      "Training loss:0.620\n",
      "Training loss:0.696\n",
      "Training loss:0.633\n",
      "Training loss:0.599\n",
      "Training loss:0.621\n",
      "Training loss:0.648\n",
      "Training loss:0.562\n",
      "Training loss:0.644\n",
      "Training loss:0.630\n",
      "Training loss:0.598\n",
      "Training loss:0.651\n",
      "Validation loss:0.624\taccuracy:0.664\n",
      "\n",
      "\n",
      "====== epoch 15 ======\n",
      "Training loss:0.620\n",
      "Training loss:0.637\n",
      "Training loss:0.626\n",
      "Training loss:0.670\n",
      "Training loss:0.631\n",
      "Training loss:0.618\n",
      "Training loss:0.709\n",
      "Training loss:0.630\n",
      "Training loss:0.639\n",
      "Training loss:0.649\n",
      "Training loss:0.642\n",
      "Training loss:0.623\n",
      "Training loss:0.618\n",
      "Training loss:0.571\n",
      "Training loss:0.635\n",
      "Training loss:0.618\n",
      "Training loss:0.624\n",
      "Training loss:0.619\n",
      "Training loss:0.624\n",
      "Training loss:0.656\n",
      "Training loss:0.691\n",
      "Training loss:0.659\n",
      "Training loss:0.624\n",
      "Training loss:0.627\n",
      "Training loss:0.645\n",
      "Training loss:0.647\n",
      "Validation loss:0.620\taccuracy:0.645\n",
      "Model saved at epoch15\n",
      "\n",
      "\n",
      "====== epoch 16 ======\n",
      "Training loss:0.603\n",
      "Training loss:0.624\n",
      "Training loss:0.592\n",
      "Training loss:0.574\n",
      "Training loss:0.656\n",
      "Training loss:0.666\n",
      "Training loss:0.625\n",
      "Training loss:0.656\n",
      "Training loss:0.678\n",
      "Training loss:0.610\n",
      "Training loss:0.650\n",
      "Training loss:0.621\n",
      "Training loss:0.673\n",
      "Training loss:0.658\n",
      "Training loss:0.650\n",
      "Training loss:0.586\n",
      "Training loss:0.625\n",
      "Training loss:0.585\n",
      "Training loss:0.664\n",
      "Training loss:0.632\n",
      "Training loss:0.603\n",
      "Training loss:0.650\n",
      "Training loss:0.644\n",
      "Training loss:0.625\n",
      "Training loss:0.648\n",
      "Training loss:0.663\n",
      "Validation loss:0.621\taccuracy:0.659\n",
      "\n",
      "\n",
      "====== epoch 17 ======\n",
      "Training loss:0.639\n",
      "Training loss:0.617\n",
      "Training loss:0.575\n",
      "Training loss:0.608\n",
      "Training loss:0.636\n",
      "Training loss:0.582\n",
      "Training loss:0.626\n",
      "Training loss:0.662\n",
      "Training loss:0.658\n",
      "Training loss:0.620\n",
      "Training loss:0.755\n",
      "Training loss:0.625\n",
      "Training loss:0.624\n",
      "Training loss:0.645\n",
      "Training loss:0.604\n",
      "Training loss:0.689\n",
      "Training loss:0.620\n",
      "Training loss:0.621\n",
      "Training loss:0.629\n",
      "Training loss:0.647\n",
      "Training loss:0.613\n",
      "Training loss:0.606\n",
      "Training loss:0.627\n",
      "Training loss:0.642\n",
      "Training loss:0.613\n",
      "Training loss:0.663\n",
      "Validation loss:0.629\taccuracy:0.659\n",
      "\n",
      "\n",
      "====== epoch 18 ======\n",
      "Training loss:0.643\n",
      "Training loss:0.661\n",
      "Training loss:0.636\n",
      "Training loss:0.625\n",
      "Training loss:0.637\n",
      "Training loss:0.617\n",
      "Training loss:0.637\n",
      "Training loss:0.623\n",
      "Training loss:0.621\n",
      "Training loss:0.700\n",
      "Training loss:0.628\n",
      "Training loss:0.591\n",
      "Training loss:0.656\n",
      "Training loss:0.642\n",
      "Training loss:0.659\n",
      "Training loss:0.608\n",
      "Training loss:0.682\n",
      "Training loss:0.631\n",
      "Training loss:0.636\n",
      "Training loss:0.642\n",
      "Training loss:0.606\n",
      "Training loss:0.658\n",
      "Training loss:0.585\n",
      "Training loss:0.600\n",
      "Training loss:0.633\n",
      "Training loss:0.614\n",
      "Validation loss:0.627\taccuracy:0.667\n",
      "\n",
      "\n",
      "====== epoch 19 ======\n",
      "Training loss:0.653\n",
      "Training loss:0.598\n",
      "Training loss:0.623\n",
      "Training loss:0.630\n",
      "Training loss:0.623\n",
      "Training loss:0.634\n",
      "Training loss:0.592\n",
      "Training loss:0.631\n",
      "Training loss:0.642\n",
      "Training loss:0.641\n",
      "Training loss:0.627\n",
      "Training loss:0.650\n",
      "Training loss:0.614\n",
      "Training loss:0.630\n",
      "Training loss:0.561\n",
      "Training loss:0.650\n",
      "Training loss:0.599\n",
      "Training loss:0.584\n",
      "Training loss:0.639\n",
      "Training loss:0.606\n",
      "Training loss:0.681\n",
      "Training loss:0.655\n",
      "Training loss:0.654\n",
      "Training loss:0.595\n",
      "Training loss:0.621\n",
      "Training loss:0.658\n",
      "Validation loss:0.618\taccuracy:0.669\n",
      "Model saved at epoch19\n",
      "\n",
      "\n",
      "====== epoch 20 ======\n",
      "Training loss:0.585\n",
      "Training loss:0.607\n",
      "Training loss:0.637\n",
      "Training loss:0.628\n",
      "Training loss:0.666\n",
      "Training loss:0.660\n",
      "Training loss:0.561\n",
      "Training loss:0.583\n",
      "Training loss:0.660\n",
      "Training loss:0.648\n",
      "Training loss:0.626\n",
      "Training loss:0.647\n",
      "Training loss:0.614\n",
      "Training loss:0.578\n",
      "Training loss:0.607\n",
      "Training loss:0.684\n",
      "Training loss:0.658\n",
      "Training loss:0.692\n",
      "Training loss:0.587\n",
      "Training loss:0.617\n",
      "Training loss:0.624\n",
      "Training loss:0.608\n",
      "Training loss:0.613\n",
      "Training loss:0.645\n",
      "Training loss:0.616\n",
      "Training loss:0.621\n",
      "Validation loss:0.622\taccuracy:0.662\n",
      "\n",
      "\n",
      "====== epoch 21 ======\n",
      "Training loss:0.644\n",
      "Training loss:0.584\n",
      "Training loss:0.626\n",
      "Training loss:0.596\n",
      "Training loss:0.633\n",
      "Training loss:0.617\n",
      "Training loss:0.632\n",
      "Training loss:0.638\n",
      "Training loss:0.575\n",
      "Training loss:0.655\n",
      "Training loss:0.604\n",
      "Training loss:0.648\n",
      "Training loss:0.632\n",
      "Training loss:0.682\n",
      "Training loss:0.639\n",
      "Training loss:0.604\n",
      "Training loss:0.589\n",
      "Training loss:0.637\n",
      "Training loss:0.628\n",
      "Training loss:0.613\n",
      "Training loss:0.638\n",
      "Training loss:0.636\n",
      "Training loss:0.622\n",
      "Training loss:0.593\n",
      "Training loss:0.595\n",
      "Training loss:0.642\n",
      "Validation loss:0.614\taccuracy:0.669\n",
      "Model saved at epoch21\n",
      "\n",
      "\n",
      "====== epoch 22 ======\n",
      "Training loss:0.599\n",
      "Training loss:0.663\n",
      "Training loss:0.561\n",
      "Training loss:0.621\n",
      "Training loss:0.546\n",
      "Training loss:0.581\n",
      "Training loss:0.645\n",
      "Training loss:0.650\n",
      "Training loss:0.629\n",
      "Training loss:0.642\n",
      "Training loss:0.595\n",
      "Training loss:0.638\n",
      "Training loss:0.578\n",
      "Training loss:0.618\n",
      "Training loss:0.644\n",
      "Training loss:0.641\n",
      "Training loss:0.604\n",
      "Training loss:0.590\n",
      "Training loss:0.667\n",
      "Training loss:0.631\n",
      "Training loss:0.610\n",
      "Training loss:0.631\n",
      "Training loss:0.634\n",
      "Training loss:0.635\n",
      "Training loss:0.667\n",
      "Training loss:0.647\n",
      "Validation loss:0.619\taccuracy:0.672\n",
      "\n",
      "\n",
      "====== epoch 23 ======\n",
      "Training loss:0.607\n",
      "Training loss:0.630\n",
      "Training loss:0.613\n",
      "Training loss:0.643\n",
      "Training loss:0.570\n",
      "Training loss:0.676\n",
      "Training loss:0.589\n",
      "Training loss:0.622\n",
      "Training loss:0.672\n",
      "Training loss:0.630\n",
      "Training loss:0.642\n",
      "Training loss:0.669\n",
      "Training loss:0.602\n",
      "Training loss:0.654\n",
      "Training loss:0.618\n",
      "Training loss:0.650\n",
      "Training loss:0.617\n",
      "Training loss:0.566\n",
      "Training loss:0.624\n",
      "Training loss:0.588\n",
      "Training loss:0.567\n",
      "Training loss:0.648\n",
      "Training loss:0.601\n",
      "Training loss:0.641\n",
      "Training loss:0.566\n",
      "Training loss:0.585\n",
      "Validation loss:0.622\taccuracy:0.679\n",
      "\n",
      "\n",
      "====== epoch 24 ======\n",
      "Training loss:0.646\n",
      "Training loss:0.622\n",
      "Training loss:0.631\n",
      "Training loss:0.580\n",
      "Training loss:0.599\n",
      "Training loss:0.616\n",
      "Training loss:0.614\n",
      "Training loss:0.608\n",
      "Training loss:0.625\n",
      "Training loss:0.613\n",
      "Training loss:0.638\n",
      "Training loss:0.592\n",
      "Training loss:0.636\n",
      "Training loss:0.617\n",
      "Training loss:0.613\n",
      "Training loss:0.573\n",
      "Training loss:0.632\n",
      "Training loss:0.609\n",
      "Training loss:0.609\n",
      "Training loss:0.675\n",
      "Training loss:0.612\n",
      "Training loss:0.604\n",
      "Training loss:0.625\n",
      "Training loss:0.616\n",
      "Training loss:0.663\n",
      "Training loss:0.614\n",
      "Validation loss:0.612\taccuracy:0.667\n",
      "Model saved at epoch24\n",
      "\n",
      "\n",
      "====== epoch 25 ======\n",
      "Training loss:0.599\n",
      "Training loss:0.568\n",
      "Training loss:0.660\n",
      "Training loss:0.590\n",
      "Training loss:0.599\n",
      "Training loss:0.612\n",
      "Training loss:0.629\n",
      "Training loss:0.612\n",
      "Training loss:0.611\n",
      "Training loss:0.570\n",
      "Training loss:0.605\n",
      "Training loss:0.599\n",
      "Training loss:0.617\n",
      "Training loss:0.700\n",
      "Training loss:0.626\n",
      "Training loss:0.626\n",
      "Training loss:0.623\n",
      "Training loss:0.616\n",
      "Training loss:0.614\n",
      "Training loss:0.637\n",
      "Training loss:0.620\n",
      "Training loss:0.638\n",
      "Training loss:0.617\n",
      "Training loss:0.659\n",
      "Training loss:0.591\n",
      "Training loss:0.599\n",
      "Validation loss:0.613\taccuracy:0.693\n",
      "\n",
      "\n",
      "====== epoch 26 ======\n",
      "Training loss:0.607\n",
      "Training loss:0.592\n",
      "Training loss:0.618\n",
      "Training loss:0.590\n",
      "Training loss:0.614\n",
      "Training loss:0.604\n",
      "Training loss:0.617\n",
      "Training loss:0.577\n",
      "Training loss:0.667\n",
      "Training loss:0.586\n",
      "Training loss:0.553\n",
      "Training loss:0.637\n",
      "Training loss:0.589\n",
      "Training loss:0.583\n",
      "Training loss:0.652\n",
      "Training loss:0.643\n",
      "Training loss:0.592\n",
      "Training loss:0.626\n",
      "Training loss:0.583\n",
      "Training loss:0.649\n",
      "Training loss:0.669\n",
      "Training loss:0.662\n",
      "Training loss:0.647\n",
      "Training loss:0.603\n",
      "Training loss:0.627\n",
      "Training loss:0.628\n",
      "Validation loss:0.620\taccuracy:0.647\n",
      "\n",
      "\n",
      "====== epoch 27 ======\n",
      "Training loss:0.626\n",
      "Training loss:0.675\n",
      "Training loss:0.679\n",
      "Training loss:0.635\n",
      "Training loss:0.606\n",
      "Training loss:0.621\n",
      "Training loss:0.622\n",
      "Training loss:0.601\n",
      "Training loss:0.631\n",
      "Training loss:0.667\n",
      "Training loss:0.690\n",
      "Training loss:0.594\n",
      "Training loss:0.605\n",
      "Training loss:0.616\n",
      "Training loss:0.662\n",
      "Training loss:0.546\n",
      "Training loss:0.591\n",
      "Training loss:0.607\n",
      "Training loss:0.630\n",
      "Training loss:0.588\n",
      "Training loss:0.588\n",
      "Training loss:0.620\n",
      "Training loss:0.553\n",
      "Training loss:0.632\n",
      "Training loss:0.570\n",
      "Training loss:0.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:0.617\taccuracy:0.684\n",
      "\n",
      "\n",
      "====== epoch 28 ======\n",
      "Training loss:0.664\n",
      "Training loss:0.634\n",
      "Training loss:0.626\n",
      "Training loss:0.594\n",
      "Training loss:0.618\n",
      "Training loss:0.616\n",
      "Training loss:0.609\n",
      "Training loss:0.603\n",
      "Training loss:0.612\n",
      "Training loss:0.589\n",
      "Training loss:0.570\n",
      "Training loss:0.596\n",
      "Training loss:0.660\n",
      "Training loss:0.583\n",
      "Training loss:0.576\n",
      "Training loss:0.642\n",
      "Training loss:0.575\n",
      "Training loss:0.651\n",
      "Training loss:0.581\n",
      "Training loss:0.591\n",
      "Training loss:0.603\n",
      "Training loss:0.525\n",
      "Training loss:0.661\n",
      "Training loss:0.725\n",
      "Training loss:0.601\n",
      "Training loss:0.659\n",
      "Validation loss:0.610\taccuracy:0.667\n",
      "Model saved at epoch28\n",
      "\n",
      "\n",
      "====== epoch 29 ======\n",
      "Training loss:0.611\n",
      "Training loss:0.623\n",
      "Training loss:0.583\n",
      "Training loss:0.599\n",
      "Training loss:0.619\n",
      "Training loss:0.682\n",
      "Training loss:0.645\n",
      "Training loss:0.651\n",
      "Training loss:0.591\n",
      "Training loss:0.568\n",
      "Training loss:0.575\n",
      "Training loss:0.620\n",
      "Training loss:0.604\n",
      "Training loss:0.615\n",
      "Training loss:0.655\n",
      "Training loss:0.539\n",
      "Training loss:0.607\n",
      "Training loss:0.608\n",
      "Training loss:0.586\n",
      "Training loss:0.567\n",
      "Training loss:0.629\n",
      "Training loss:0.592\n",
      "Training loss:0.605\n",
      "Training loss:0.617\n",
      "Training loss:0.574\n",
      "Training loss:0.691\n",
      "Validation loss:0.613\taccuracy:0.676\n",
      "\n",
      "\n",
      "====== epoch 30 ======\n",
      "Training loss:0.626\n",
      "Training loss:0.598\n",
      "Training loss:0.621\n",
      "Training loss:0.578\n",
      "Training loss:0.582\n",
      "Training loss:0.612\n",
      "Training loss:0.601\n",
      "Training loss:0.572\n",
      "Training loss:0.598\n",
      "Training loss:0.600\n",
      "Training loss:0.625\n",
      "Training loss:0.604\n",
      "Training loss:0.578\n",
      "Training loss:0.564\n",
      "Training loss:0.605\n",
      "Training loss:0.589\n",
      "Training loss:0.617\n",
      "Training loss:0.624\n",
      "Training loss:0.645\n",
      "Training loss:0.647\n",
      "Training loss:0.598\n",
      "Training loss:0.601\n",
      "Training loss:0.652\n",
      "Training loss:0.607\n",
      "Training loss:0.663\n",
      "Training loss:0.565\n",
      "Validation loss:0.610\taccuracy:0.686\n",
      "\n",
      "\n",
      "====== epoch 31 ======\n",
      "Training loss:0.622\n",
      "Training loss:0.654\n",
      "Training loss:0.580\n",
      "Training loss:0.573\n",
      "Training loss:0.675\n",
      "Training loss:0.577\n",
      "Training loss:0.583\n",
      "Training loss:0.566\n",
      "Training loss:0.641\n",
      "Training loss:0.548\n",
      "Training loss:0.667\n",
      "Training loss:0.637\n",
      "Training loss:0.665\n",
      "Training loss:0.548\n",
      "Training loss:0.607\n",
      "Training loss:0.580\n",
      "Training loss:0.573\n",
      "Training loss:0.610\n",
      "Training loss:0.626\n",
      "Training loss:0.645\n",
      "Training loss:0.593\n",
      "Training loss:0.644\n",
      "Training loss:0.610\n",
      "Training loss:0.548\n",
      "Training loss:0.581\n",
      "Training loss:0.620\n",
      "Validation loss:0.608\taccuracy:0.674\n",
      "Model saved at epoch31\n",
      "\n",
      "\n",
      "====== epoch 32 ======\n",
      "Training loss:0.581\n",
      "Training loss:0.601\n",
      "Training loss:0.521\n",
      "Training loss:0.615\n",
      "Training loss:0.693\n",
      "Training loss:0.610\n",
      "Training loss:0.590\n",
      "Training loss:0.591\n",
      "Training loss:0.631\n",
      "Training loss:0.569\n",
      "Training loss:0.585\n",
      "Training loss:0.623\n",
      "Training loss:0.618\n",
      "Training loss:0.608\n",
      "Training loss:0.538\n",
      "Training loss:0.579\n",
      "Training loss:0.542\n",
      "Training loss:0.615\n",
      "Training loss:0.639\n",
      "Training loss:0.617\n",
      "Training loss:0.637\n",
      "Training loss:0.645\n",
      "Training loss:0.580\n",
      "Training loss:0.631\n",
      "Training loss:0.582\n",
      "Training loss:0.668\n",
      "Validation loss:0.606\taccuracy:0.662\n",
      "Model saved at epoch32\n",
      "\n",
      "\n",
      "====== epoch 33 ======\n",
      "Training loss:0.610\n",
      "Training loss:0.592\n",
      "Training loss:0.605\n",
      "Training loss:0.572\n",
      "Training loss:0.587\n",
      "Training loss:0.601\n",
      "Training loss:0.619\n",
      "Training loss:0.572\n",
      "Training loss:0.675\n",
      "Training loss:0.645\n",
      "Training loss:0.597\n",
      "Training loss:0.622\n",
      "Training loss:0.611\n",
      "Training loss:0.562\n",
      "Training loss:0.554\n",
      "Training loss:0.614\n",
      "Training loss:0.629\n",
      "Training loss:0.626\n",
      "Training loss:0.629\n",
      "Training loss:0.547\n",
      "Training loss:0.563\n",
      "Training loss:0.609\n",
      "Training loss:0.595\n",
      "Training loss:0.577\n",
      "Training loss:0.663\n",
      "Training loss:0.616\n",
      "Validation loss:0.608\taccuracy:0.662\n",
      "\n",
      "\n",
      "====== epoch 34 ======\n",
      "Training loss:0.589\n",
      "Training loss:0.556\n",
      "Training loss:0.652\n",
      "Training loss:0.604\n",
      "Training loss:0.622\n",
      "Training loss:0.628\n",
      "Training loss:0.560\n",
      "Training loss:0.548\n",
      "Training loss:0.599\n",
      "Training loss:0.596\n",
      "Training loss:0.593\n",
      "Training loss:0.557\n",
      "Training loss:0.583\n",
      "Training loss:0.617\n",
      "Training loss:0.644\n",
      "Training loss:0.680\n",
      "Training loss:0.601\n",
      "Training loss:0.614\n",
      "Training loss:0.623\n",
      "Training loss:0.678\n",
      "Training loss:0.561\n",
      "Training loss:0.579\n",
      "Training loss:0.561\n",
      "Training loss:0.623\n",
      "Training loss:0.608\n",
      "Training loss:0.606\n",
      "Validation loss:0.604\taccuracy:0.664\n",
      "Model saved at epoch34\n",
      "\n",
      "\n",
      "====== epoch 35 ======\n",
      "Training loss:0.546\n",
      "Training loss:0.631\n",
      "Training loss:0.584\n",
      "Training loss:0.568\n",
      "Training loss:0.603\n",
      "Training loss:0.598\n",
      "Training loss:0.610\n",
      "Training loss:0.550\n",
      "Training loss:0.646\n",
      "Training loss:0.632\n",
      "Training loss:0.617\n",
      "Training loss:0.616\n",
      "Training loss:0.614\n",
      "Training loss:0.556\n",
      "Training loss:0.634\n",
      "Training loss:0.650\n",
      "Training loss:0.617\n",
      "Training loss:0.567\n",
      "Training loss:0.623\n",
      "Training loss:0.610\n",
      "Training loss:0.599\n",
      "Training loss:0.603\n",
      "Training loss:0.598\n",
      "Training loss:0.615\n",
      "Training loss:0.568\n",
      "Training loss:0.584\n",
      "Validation loss:0.601\taccuracy:0.689\n",
      "Model saved at epoch35\n",
      "\n",
      "\n",
      "====== epoch 36 ======\n",
      "Training loss:0.597\n",
      "Training loss:0.648\n",
      "Training loss:0.592\n",
      "Training loss:0.606\n",
      "Training loss:0.621\n",
      "Training loss:0.544\n",
      "Training loss:0.648\n",
      "Training loss:0.605\n",
      "Training loss:0.553\n",
      "Training loss:0.581\n",
      "Training loss:0.642\n",
      "Training loss:0.597\n",
      "Training loss:0.567\n",
      "Training loss:0.654\n",
      "Training loss:0.556\n",
      "Training loss:0.615\n",
      "Training loss:0.593\n",
      "Training loss:0.609\n",
      "Training loss:0.588\n",
      "Training loss:0.626\n",
      "Training loss:0.559\n",
      "Training loss:0.591\n",
      "Training loss:0.615\n",
      "Training loss:0.641\n",
      "Training loss:0.606\n",
      "Training loss:0.645\n",
      "Validation loss:0.599\taccuracy:0.681\n",
      "Model saved at epoch36\n",
      "\n",
      "\n",
      "====== epoch 37 ======\n",
      "Training loss:0.590\n",
      "Training loss:0.664\n",
      "Training loss:0.613\n",
      "Training loss:0.585\n",
      "Training loss:0.592\n",
      "Training loss:0.586\n",
      "Training loss:0.588\n",
      "Training loss:0.607\n",
      "Training loss:0.683\n",
      "Training loss:0.611\n",
      "Training loss:0.555\n",
      "Training loss:0.549\n",
      "Training loss:0.560\n",
      "Training loss:0.615\n",
      "Training loss:0.563\n",
      "Training loss:0.590\n",
      "Training loss:0.526\n",
      "Training loss:0.637\n",
      "Training loss:0.565\n",
      "Training loss:0.629\n",
      "Training loss:0.604\n",
      "Training loss:0.644\n",
      "Training loss:0.607\n",
      "Training loss:0.587\n",
      "Training loss:0.564\n",
      "Training loss:0.673\n",
      "Validation loss:0.612\taccuracy:0.681\n",
      "\n",
      "\n",
      "====== epoch 38 ======\n",
      "Training loss:0.590\n",
      "Training loss:0.574\n",
      "Training loss:0.579\n",
      "Training loss:0.667\n",
      "Training loss:0.607\n",
      "Training loss:0.543\n",
      "Training loss:0.571\n",
      "Training loss:0.604\n",
      "Training loss:0.647\n",
      "Training loss:0.615\n",
      "Training loss:0.628\n",
      "Training loss:0.621\n",
      "Training loss:0.619\n",
      "Training loss:0.609\n",
      "Training loss:0.572\n",
      "Training loss:0.588\n",
      "Training loss:0.559\n",
      "Training loss:0.578\n",
      "Training loss:0.631\n",
      "Training loss:0.630\n",
      "Training loss:0.590\n",
      "Training loss:0.578\n",
      "Training loss:0.601\n",
      "Training loss:0.607\n",
      "Training loss:0.559\n",
      "Training loss:0.588\n",
      "Validation loss:0.600\taccuracy:0.674\n",
      "\n",
      "\n",
      "====== epoch 39 ======\n",
      "Training loss:0.508\n",
      "Training loss:0.551\n",
      "Training loss:0.579\n",
      "Training loss:0.637\n",
      "Training loss:0.561\n",
      "Training loss:0.600\n",
      "Training loss:0.629\n",
      "Training loss:0.540\n",
      "Training loss:0.595\n",
      "Training loss:0.636\n",
      "Training loss:0.539\n",
      "Training loss:0.683\n",
      "Training loss:0.536\n",
      "Training loss:0.550\n",
      "Training loss:0.545\n",
      "Training loss:0.540\n",
      "Training loss:0.622\n",
      "Training loss:0.632\n",
      "Training loss:0.578\n",
      "Training loss:0.607\n",
      "Training loss:0.585\n",
      "Training loss:0.598\n",
      "Training loss:0.642\n",
      "Training loss:0.629\n",
      "Training loss:0.623\n",
      "Training loss:0.654\n",
      "Validation loss:0.599\taccuracy:0.686\n",
      "\n",
      "\n",
      "====== epoch 40 ======\n",
      "Training loss:0.552\n",
      "Training loss:0.580\n",
      "Training loss:0.555\n",
      "Training loss:0.613\n",
      "Training loss:0.592\n",
      "Training loss:0.551\n",
      "Training loss:0.641\n",
      "Training loss:0.607\n",
      "Training loss:0.589\n",
      "Training loss:0.597\n",
      "Training loss:0.649\n",
      "Training loss:0.565\n",
      "Training loss:0.594\n",
      "Training loss:0.614\n",
      "Training loss:0.602\n",
      "Training loss:0.551\n",
      "Training loss:0.568\n",
      "Training loss:0.602\n",
      "Training loss:0.554\n",
      "Training loss:0.619\n",
      "Training loss:0.578\n",
      "Training loss:0.608\n",
      "Training loss:0.623\n",
      "Training loss:0.557\n",
      "Training loss:0.654\n",
      "Training loss:0.572\n",
      "Validation loss:0.592\taccuracy:0.674\n",
      "Model saved at epoch40\n",
      "\n",
      "\n",
      "====== epoch 41 ======\n",
      "Training loss:0.599\n",
      "Training loss:0.617\n",
      "Training loss:0.620\n",
      "Training loss:0.522\n",
      "Training loss:0.600\n",
      "Training loss:0.612\n",
      "Training loss:0.526\n",
      "Training loss:0.645\n",
      "Training loss:0.569\n",
      "Training loss:0.586\n",
      "Training loss:0.597\n",
      "Training loss:0.579\n",
      "Training loss:0.602\n",
      "Training loss:0.544\n",
      "Training loss:0.582\n",
      "Training loss:0.636\n",
      "Training loss:0.604\n",
      "Training loss:0.556\n",
      "Training loss:0.526\n",
      "Training loss:0.581\n",
      "Training loss:0.597\n",
      "Training loss:0.641\n",
      "Training loss:0.590\n",
      "Training loss:0.602\n",
      "Training loss:0.601\n",
      "Training loss:0.584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:0.604\taccuracy:0.676\n",
      "\n",
      "\n",
      "====== epoch 42 ======\n",
      "Training loss:0.614\n",
      "Training loss:0.543\n",
      "Training loss:0.610\n",
      "Training loss:0.653\n",
      "Training loss:0.592\n",
      "Training loss:0.584\n",
      "Training loss:0.526\n",
      "Training loss:0.609\n",
      "Training loss:0.626\n",
      "Training loss:0.565\n",
      "Training loss:0.597\n",
      "Training loss:0.585\n",
      "Training loss:0.598\n",
      "Training loss:0.515\n",
      "Training loss:0.527\n",
      "Training loss:0.617\n",
      "Training loss:0.558\n",
      "Training loss:0.640\n",
      "Training loss:0.590\n",
      "Training loss:0.613\n",
      "Training loss:0.618\n",
      "Training loss:0.596\n",
      "Training loss:0.556\n",
      "Training loss:0.632\n",
      "Training loss:0.623\n",
      "Training loss:0.609\n",
      "Validation loss:0.611\taccuracy:0.674\n",
      "\n",
      "\n",
      "====== epoch 43 ======\n",
      "Training loss:0.610\n",
      "Training loss:0.592\n",
      "Training loss:0.551\n",
      "Training loss:0.646\n",
      "Training loss:0.593\n",
      "Training loss:0.574\n",
      "Training loss:0.569\n",
      "Training loss:0.587\n",
      "Training loss:0.608\n",
      "Training loss:0.587\n",
      "Training loss:0.575\n",
      "Training loss:0.539\n",
      "Training loss:0.586\n",
      "Training loss:0.571\n",
      "Training loss:0.576\n",
      "Training loss:0.547\n",
      "Training loss:0.554\n",
      "Training loss:0.615\n",
      "Training loss:0.633\n",
      "Training loss:0.562\n",
      "Training loss:0.626\n",
      "Training loss:0.621\n",
      "Training loss:0.590\n",
      "Training loss:0.608\n",
      "Training loss:0.513\n",
      "Training loss:0.560\n",
      "Validation loss:0.590\taccuracy:0.701\n",
      "Model saved at epoch43\n",
      "\n",
      "\n",
      "====== epoch 44 ======\n",
      "Training loss:0.593\n",
      "Training loss:0.588\n",
      "Training loss:0.579\n",
      "Training loss:0.589\n",
      "Training loss:0.593\n",
      "Training loss:0.577\n",
      "Training loss:0.617\n",
      "Training loss:0.532\n",
      "Training loss:0.605\n",
      "Training loss:0.588\n",
      "Training loss:0.579\n",
      "Training loss:0.522\n",
      "Training loss:0.606\n",
      "Training loss:0.600\n",
      "Training loss:0.617\n",
      "Training loss:0.541\n",
      "Training loss:0.562\n",
      "Training loss:0.605\n",
      "Training loss:0.614\n",
      "Training loss:0.552\n",
      "Training loss:0.591\n",
      "Training loss:0.618\n",
      "Training loss:0.598\n",
      "Training loss:0.634\n",
      "Training loss:0.628\n",
      "Training loss:0.568\n",
      "Validation loss:0.591\taccuracy:0.691\n",
      "\n",
      "\n",
      "====== epoch 45 ======\n",
      "Training loss:0.563\n",
      "Training loss:0.558\n",
      "Training loss:0.618\n",
      "Training loss:0.556\n",
      "Training loss:0.568\n",
      "Training loss:0.541\n",
      "Training loss:0.628\n",
      "Training loss:0.543\n",
      "Training loss:0.656\n",
      "Training loss:0.603\n",
      "Training loss:0.562\n",
      "Training loss:0.552\n",
      "Training loss:0.572\n",
      "Training loss:0.630\n",
      "Training loss:0.537\n",
      "Training loss:0.622\n",
      "Training loss:0.589\n",
      "Training loss:0.603\n",
      "Training loss:0.534\n",
      "Training loss:0.579\n",
      "Training loss:0.660\n",
      "Training loss:0.592\n",
      "Training loss:0.570\n",
      "Training loss:0.569\n",
      "Training loss:0.614\n",
      "Training loss:0.585\n",
      "Validation loss:0.591\taccuracy:0.698\n",
      "\n",
      "\n",
      "====== epoch 46 ======\n",
      "Training loss:0.576\n",
      "Training loss:0.656\n",
      "Training loss:0.591\n",
      "Training loss:0.551\n",
      "Training loss:0.585\n",
      "Training loss:0.590\n",
      "Training loss:0.571\n",
      "Training loss:0.527\n",
      "Training loss:0.617\n",
      "Training loss:0.601\n",
      "Training loss:0.574\n",
      "Training loss:0.641\n",
      "Training loss:0.555\n",
      "Training loss:0.592\n",
      "Training loss:0.599\n",
      "Training loss:0.562\n",
      "Training loss:0.609\n",
      "Training loss:0.551\n",
      "Training loss:0.582\n",
      "Training loss:0.570\n",
      "Training loss:0.534\n",
      "Training loss:0.639\n",
      "Training loss:0.621\n",
      "Training loss:0.602\n",
      "Training loss:0.552\n",
      "Training loss:0.529\n",
      "Validation loss:0.588\taccuracy:0.696\n",
      "Model saved at epoch46\n",
      "\n",
      "\n",
      "====== epoch 47 ======\n",
      "Training loss:0.585\n",
      "Training loss:0.582\n",
      "Training loss:0.583\n",
      "Training loss:0.564\n",
      "Training loss:0.565\n",
      "Training loss:0.608\n",
      "Training loss:0.567\n",
      "Training loss:0.592\n",
      "Training loss:0.543\n",
      "Training loss:0.686\n",
      "Training loss:0.562\n",
      "Training loss:0.568\n",
      "Training loss:0.624\n",
      "Training loss:0.567\n",
      "Training loss:0.607\n",
      "Training loss:0.585\n",
      "Training loss:0.591\n",
      "Training loss:0.651\n",
      "Training loss:0.627\n",
      "Training loss:0.630\n",
      "Training loss:0.558\n",
      "Training loss:0.595\n",
      "Training loss:0.617\n",
      "Training loss:0.596\n",
      "Training loss:0.634\n",
      "Training loss:0.546\n",
      "Validation loss:0.591\taccuracy:0.710\n",
      "\n",
      "\n",
      "====== epoch 48 ======\n",
      "Training loss:0.579\n",
      "Training loss:0.567\n",
      "Training loss:0.572\n",
      "Training loss:0.622\n",
      "Training loss:0.573\n",
      "Training loss:0.569\n",
      "Training loss:0.575\n",
      "Training loss:0.537\n",
      "Training loss:0.563\n",
      "Training loss:0.636\n",
      "Training loss:0.630\n",
      "Training loss:0.536\n",
      "Training loss:0.616\n",
      "Training loss:0.608\n",
      "Training loss:0.552\n",
      "Training loss:0.572\n",
      "Training loss:0.538\n",
      "Training loss:0.618\n",
      "Training loss:0.648\n",
      "Training loss:0.545\n",
      "Training loss:0.546\n",
      "Training loss:0.655\n",
      "Training loss:0.614\n",
      "Training loss:0.579\n",
      "Training loss:0.543\n",
      "Training loss:0.594\n",
      "Validation loss:0.590\taccuracy:0.674\n",
      "\n",
      "\n",
      "====== epoch 49 ======\n",
      "Training loss:0.543\n",
      "Training loss:0.631\n",
      "Training loss:0.541\n",
      "Training loss:0.573\n",
      "Training loss:0.605\n",
      "Training loss:0.622\n",
      "Training loss:0.615\n",
      "Training loss:0.598\n",
      "Training loss:0.595\n",
      "Training loss:0.583\n",
      "Training loss:0.610\n",
      "Training loss:0.585\n",
      "Training loss:0.604\n",
      "Training loss:0.566\n",
      "Training loss:0.624\n",
      "Training loss:0.555\n",
      "Training loss:0.622\n",
      "Training loss:0.639\n",
      "Training loss:0.641\n",
      "Training loss:0.501\n",
      "Training loss:0.587\n",
      "Training loss:0.554\n",
      "Training loss:0.649\n",
      "Training loss:0.574\n",
      "Training loss:0.577\n",
      "Training loss:0.528\n",
      "Validation loss:0.593\taccuracy:0.679\n",
      "\n",
      "\n",
      "====== epoch 50 ======\n",
      "Training loss:0.621\n",
      "Training loss:0.584\n",
      "Training loss:0.539\n",
      "Training loss:0.636\n",
      "Training loss:0.533\n",
      "Training loss:0.543\n",
      "Training loss:0.580\n",
      "Training loss:0.569\n",
      "Training loss:0.557\n",
      "Training loss:0.615\n",
      "Training loss:0.554\n",
      "Training loss:0.613\n",
      "Training loss:0.680\n",
      "Training loss:0.579\n",
      "Training loss:0.662\n",
      "Training loss:0.599\n",
      "Training loss:0.573\n",
      "Training loss:0.577\n",
      "Training loss:0.571\n",
      "Training loss:0.629\n",
      "Training loss:0.603\n",
      "Training loss:0.593\n",
      "Training loss:0.544\n",
      "Training loss:0.580\n",
      "Training loss:0.552\n",
      "Training loss:0.579\n",
      "Validation loss:0.595\taccuracy:0.679\n",
      "\n",
      "\n",
      "====== epoch 51 ======\n",
      "Training loss:0.578\n",
      "Training loss:0.568\n",
      "Training loss:0.616\n",
      "Training loss:0.601\n",
      "Training loss:0.581\n",
      "Training loss:0.623\n",
      "Training loss:0.549\n",
      "Training loss:0.559\n",
      "Training loss:0.583\n",
      "Training loss:0.541\n",
      "Training loss:0.576\n",
      "Training loss:0.600\n",
      "Training loss:0.623\n",
      "Training loss:0.545\n",
      "Training loss:0.629\n",
      "Training loss:0.563\n",
      "Training loss:0.622\n",
      "Training loss:0.562\n",
      "Training loss:0.543\n",
      "Training loss:0.566\n",
      "Training loss:0.623\n",
      "Training loss:0.633\n",
      "Training loss:0.521\n",
      "Training loss:0.645\n",
      "Training loss:0.581\n",
      "Training loss:0.532\n",
      "Validation loss:0.615\taccuracy:0.676\n",
      "\n",
      "\n",
      "====== epoch 52 ======\n",
      "Training loss:0.606\n",
      "Training loss:0.619\n",
      "Training loss:0.551\n",
      "Training loss:0.608\n",
      "Training loss:0.601\n",
      "Training loss:0.579\n",
      "Training loss:0.558\n",
      "Training loss:0.583\n",
      "Training loss:0.621\n",
      "Training loss:0.594\n",
      "Training loss:0.532\n",
      "Training loss:0.590\n",
      "Training loss:0.602\n",
      "Training loss:0.585\n",
      "Training loss:0.610\n",
      "Training loss:0.543\n",
      "Training loss:0.567\n",
      "Training loss:0.541\n",
      "Training loss:0.567\n",
      "Training loss:0.664\n",
      "Training loss:0.553\n",
      "Training loss:0.640\n",
      "Training loss:0.596\n",
      "Training loss:0.542\n",
      "Training loss:0.592\n",
      "Training loss:0.558\n",
      "Validation loss:0.590\taccuracy:0.689\n",
      "\n",
      "\n",
      "====== epoch 53 ======\n",
      "Training loss:0.605\n",
      "Training loss:0.500\n",
      "Training loss:0.563\n",
      "Training loss:0.606\n",
      "Training loss:0.559\n",
      "Training loss:0.555\n",
      "Training loss:0.552\n",
      "Training loss:0.592\n",
      "Training loss:0.557\n",
      "Training loss:0.555\n",
      "Training loss:0.551\n",
      "Training loss:0.648\n",
      "Training loss:0.576\n",
      "Training loss:0.625\n",
      "Training loss:0.516\n",
      "Training loss:0.612\n",
      "Training loss:0.597\n",
      "Training loss:0.570\n",
      "Training loss:0.571\n",
      "Training loss:0.587\n",
      "Training loss:0.615\n",
      "Training loss:0.590\n",
      "Training loss:0.578\n",
      "Training loss:0.541\n",
      "Training loss:0.606\n",
      "Training loss:0.563\n",
      "Validation loss:0.604\taccuracy:0.669\n",
      "\n",
      "\n",
      "====== epoch 54 ======\n",
      "Training loss:0.528\n",
      "Training loss:0.555\n",
      "Training loss:0.567\n",
      "Training loss:0.567\n",
      "Training loss:0.582\n",
      "Training loss:0.556\n",
      "Training loss:0.597\n",
      "Training loss:0.561\n",
      "Training loss:0.574\n",
      "Training loss:0.594\n",
      "Training loss:0.571\n",
      "Training loss:0.557\n",
      "Training loss:0.566\n",
      "Training loss:0.652\n",
      "Training loss:0.656\n",
      "Training loss:0.626\n",
      "Training loss:0.552\n",
      "Training loss:0.630\n",
      "Training loss:0.593\n",
      "Training loss:0.592\n",
      "Training loss:0.531\n",
      "Training loss:0.511\n",
      "Training loss:0.633\n",
      "Training loss:0.601\n",
      "Training loss:0.600\n",
      "Training loss:0.585\n",
      "Validation loss:0.586\taccuracy:0.701\n",
      "Model saved at epoch54\n",
      "\n",
      "\n",
      "====== epoch 55 ======\n",
      "Training loss:0.618\n",
      "Training loss:0.579\n",
      "Training loss:0.614\n",
      "Training loss:0.559\n",
      "Training loss:0.662\n",
      "Training loss:0.557\n",
      "Training loss:0.588\n",
      "Training loss:0.604\n",
      "Training loss:0.611\n",
      "Training loss:0.563\n",
      "Training loss:0.600\n",
      "Training loss:0.515\n",
      "Training loss:0.606\n",
      "Training loss:0.568\n",
      "Training loss:0.515\n",
      "Training loss:0.640\n",
      "Training loss:0.587\n",
      "Training loss:0.622\n",
      "Training loss:0.514\n",
      "Training loss:0.530\n",
      "Training loss:0.557\n",
      "Training loss:0.599\n",
      "Training loss:0.547\n",
      "Training loss:0.563\n",
      "Training loss:0.542\n",
      "Training loss:0.548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:0.592\taccuracy:0.691\n",
      "\n",
      "\n",
      "====== epoch 56 ======\n",
      "Training loss:0.637\n",
      "Training loss:0.545\n",
      "Training loss:0.567\n",
      "Training loss:0.552\n",
      "Training loss:0.590\n",
      "Training loss:0.568\n",
      "Training loss:0.598\n",
      "Training loss:0.565\n",
      "Training loss:0.631\n",
      "Training loss:0.550\n",
      "Training loss:0.505\n",
      "Training loss:0.502\n",
      "Training loss:0.594\n",
      "Training loss:0.558\n",
      "Training loss:0.652\n",
      "Training loss:0.599\n",
      "Training loss:0.596\n",
      "Training loss:0.612\n",
      "Training loss:0.567\n",
      "Training loss:0.565\n",
      "Training loss:0.557\n",
      "Training loss:0.550\n",
      "Training loss:0.614\n",
      "Training loss:0.564\n",
      "Training loss:0.493\n",
      "Training loss:0.572\n",
      "Validation loss:0.599\taccuracy:0.674\n",
      "\n",
      "\n",
      "====== epoch 57 ======\n",
      "Training loss:0.596\n",
      "Training loss:0.551\n",
      "Training loss:0.619\n",
      "Training loss:0.567\n",
      "Training loss:0.506\n",
      "Training loss:0.557\n",
      "Training loss:0.555\n",
      "Training loss:0.593\n",
      "Training loss:0.556\n",
      "Training loss:0.543\n",
      "Training loss:0.555\n",
      "Training loss:0.617\n",
      "Training loss:0.571\n",
      "Training loss:0.604\n",
      "Training loss:0.639\n",
      "Training loss:0.549\n",
      "Training loss:0.576\n",
      "Training loss:0.612\n",
      "Training loss:0.646\n",
      "Training loss:0.549\n",
      "Training loss:0.526\n",
      "Training loss:0.608\n",
      "Training loss:0.585\n",
      "Training loss:0.519\n",
      "Training loss:0.563\n",
      "Training loss:0.545\n",
      "Validation loss:0.593\taccuracy:0.684\n",
      "\n",
      "\n",
      "====== epoch 58 ======\n",
      "Training loss:0.566\n",
      "Training loss:0.567\n",
      "Training loss:0.594\n",
      "Training loss:0.578\n",
      "Training loss:0.582\n",
      "Training loss:0.589\n",
      "Training loss:0.639\n",
      "Training loss:0.586\n",
      "Training loss:0.547\n",
      "Training loss:0.516\n",
      "Training loss:0.558\n",
      "Training loss:0.556\n",
      "Training loss:0.644\n",
      "Training loss:0.607\n",
      "Training loss:0.575\n",
      "Training loss:0.546\n",
      "Training loss:0.618\n",
      "Training loss:0.576\n",
      "Training loss:0.563\n",
      "Training loss:0.641\n",
      "Training loss:0.642\n",
      "Training loss:0.550\n",
      "Training loss:0.532\n",
      "Training loss:0.566\n",
      "Training loss:0.586\n",
      "Training loss:0.535\n",
      "Validation loss:0.600\taccuracy:0.676\n",
      "\n",
      "\n",
      "====== epoch 59 ======\n",
      "Training loss:0.629\n",
      "Training loss:0.549\n",
      "Training loss:0.556\n",
      "Training loss:0.531\n",
      "Training loss:0.562\n",
      "Training loss:0.611\n",
      "Training loss:0.549\n",
      "Training loss:0.571\n",
      "Training loss:0.523\n",
      "Training loss:0.588\n",
      "Training loss:0.574\n",
      "Training loss:0.635\n",
      "Training loss:0.590\n",
      "Training loss:0.542\n",
      "Training loss:0.614\n",
      "Training loss:0.552\n",
      "Training loss:0.635\n",
      "Training loss:0.548\n",
      "Training loss:0.570\n",
      "Training loss:0.576\n",
      "Training loss:0.532\n",
      "Training loss:0.576\n",
      "Training loss:0.576\n",
      "Training loss:0.568\n",
      "Training loss:0.612\n",
      "Training loss:0.513\n",
      "Validation loss:0.597\taccuracy:0.679\n",
      "\n",
      "\n",
      "====== epoch 60 ======\n",
      "Training loss:0.594\n",
      "Training loss:0.563\n",
      "Training loss:0.495\n",
      "Training loss:0.583\n",
      "Training loss:0.525\n",
      "Training loss:0.581\n",
      "Training loss:0.644\n",
      "Training loss:0.514\n",
      "Training loss:0.592\n",
      "Training loss:0.557\n",
      "Training loss:0.583\n",
      "Training loss:0.591\n",
      "Training loss:0.564\n",
      "Training loss:0.550\n",
      "Training loss:0.556\n",
      "Training loss:0.548\n",
      "Training loss:0.525\n",
      "Training loss:0.534\n",
      "Training loss:0.630\n",
      "Training loss:0.672\n",
      "Training loss:0.575\n",
      "Training loss:0.543\n",
      "Training loss:0.560\n",
      "Training loss:0.579\n",
      "Training loss:0.642\n",
      "Training loss:0.584\n",
      "Validation loss:0.587\taccuracy:0.703\n",
      "\n",
      "\n",
      "====== epoch 61 ======\n",
      "Training loss:0.580\n",
      "Training loss:0.521\n",
      "Training loss:0.527\n",
      "Training loss:0.577\n",
      "Training loss:0.549\n",
      "Training loss:0.580\n",
      "Training loss:0.567\n",
      "Training loss:0.574\n",
      "Training loss:0.578\n",
      "Training loss:0.607\n",
      "Training loss:0.590\n",
      "Training loss:0.636\n",
      "Training loss:0.546\n",
      "Training loss:0.559\n",
      "Training loss:0.579\n",
      "Training loss:0.539\n",
      "Training loss:0.555\n",
      "Training loss:0.548\n",
      "Training loss:0.543\n",
      "Training loss:0.549\n",
      "Training loss:0.601\n",
      "Training loss:0.695\n",
      "Training loss:0.617\n",
      "Training loss:0.520\n",
      "Training loss:0.574\n",
      "Training loss:0.532\n",
      "Validation loss:0.581\taccuracy:0.689\n",
      "Model saved at epoch61\n",
      "\n",
      "\n",
      "====== epoch 62 ======\n",
      "Training loss:0.577\n",
      "Training loss:0.559\n",
      "Training loss:0.541\n",
      "Training loss:0.574\n",
      "Training loss:0.598\n",
      "Training loss:0.572\n",
      "Training loss:0.619\n",
      "Training loss:0.579\n",
      "Training loss:0.566\n",
      "Training loss:0.610\n",
      "Training loss:0.544\n",
      "Training loss:0.566\n",
      "Training loss:0.522\n",
      "Training loss:0.598\n",
      "Training loss:0.520\n",
      "Training loss:0.584\n",
      "Training loss:0.540\n",
      "Training loss:0.543\n",
      "Training loss:0.579\n",
      "Training loss:0.567\n",
      "Training loss:0.544\n",
      "Training loss:0.595\n",
      "Training loss:0.612\n",
      "Training loss:0.562\n",
      "Training loss:0.562\n",
      "Training loss:0.622\n",
      "Validation loss:0.601\taccuracy:0.681\n",
      "\n",
      "\n",
      "====== epoch 63 ======\n",
      "Training loss:0.542\n",
      "Training loss:0.535\n",
      "Training loss:0.573\n",
      "Training loss:0.538\n",
      "Training loss:0.602\n",
      "Training loss:0.618\n",
      "Training loss:0.599\n",
      "Training loss:0.543\n",
      "Training loss:0.496\n",
      "Training loss:0.569\n",
      "Training loss:0.603\n",
      "Training loss:0.572\n",
      "Training loss:0.481\n",
      "Training loss:0.565\n",
      "Training loss:0.626\n",
      "Training loss:0.496\n",
      "Training loss:0.614\n",
      "Training loss:0.633\n",
      "Training loss:0.582\n",
      "Training loss:0.552\n",
      "Training loss:0.623\n",
      "Training loss:0.559\n",
      "Training loss:0.556\n",
      "Training loss:0.631\n",
      "Training loss:0.594\n",
      "Training loss:0.602\n",
      "Validation loss:0.590\taccuracy:0.686\n",
      "\n",
      "\n",
      "====== epoch 64 ======\n",
      "Training loss:0.565\n",
      "Training loss:0.557\n",
      "Training loss:0.571\n",
      "Training loss:0.646\n",
      "Training loss:0.586\n",
      "Training loss:0.512\n",
      "Training loss:0.567\n",
      "Training loss:0.508\n",
      "Training loss:0.573\n",
      "Training loss:0.556\n",
      "Training loss:0.562\n",
      "Training loss:0.567\n",
      "Training loss:0.577\n",
      "Training loss:0.632\n",
      "Training loss:0.634\n",
      "Training loss:0.570\n",
      "Training loss:0.595\n",
      "Training loss:0.549\n",
      "Training loss:0.556\n",
      "Training loss:0.536\n",
      "Training loss:0.609\n",
      "Training loss:0.546\n",
      "Training loss:0.599\n",
      "Training loss:0.549\n",
      "Training loss:0.602\n",
      "Training loss:0.575\n",
      "Validation loss:0.580\taccuracy:0.708\n",
      "Model saved at epoch64\n",
      "\n",
      "\n",
      "====== epoch 65 ======\n",
      "Training loss:0.441\n",
      "Training loss:0.582\n",
      "Training loss:0.607\n",
      "Training loss:0.493\n",
      "Training loss:0.600\n",
      "Training loss:0.520\n",
      "Training loss:0.560\n",
      "Training loss:0.637\n",
      "Training loss:0.572\n",
      "Training loss:0.517\n",
      "Training loss:0.584\n",
      "Training loss:0.567\n",
      "Training loss:0.646\n",
      "Training loss:0.555\n",
      "Training loss:0.540\n",
      "Training loss:0.635\n",
      "Training loss:0.509\n",
      "Training loss:0.520\n",
      "Training loss:0.569\n",
      "Training loss:0.591\n",
      "Training loss:0.604\n",
      "Training loss:0.607\n",
      "Training loss:0.606\n",
      "Training loss:0.564\n",
      "Training loss:0.557\n",
      "Training loss:0.641\n",
      "Validation loss:0.582\taccuracy:0.713\n",
      "\n",
      "\n",
      "====== epoch 66 ======\n",
      "Training loss:0.600\n",
      "Training loss:0.576\n",
      "Training loss:0.635\n",
      "Training loss:0.575\n",
      "Training loss:0.597\n",
      "Training loss:0.539\n",
      "Training loss:0.576\n",
      "Training loss:0.529\n",
      "Training loss:0.568\n",
      "Training loss:0.562\n",
      "Training loss:0.564\n",
      "Training loss:0.587\n",
      "Training loss:0.536\n",
      "Training loss:0.503\n",
      "Training loss:0.610\n",
      "Training loss:0.616\n",
      "Training loss:0.527\n",
      "Training loss:0.555\n",
      "Training loss:0.633\n",
      "Training loss:0.473\n",
      "Training loss:0.579\n",
      "Training loss:0.572\n",
      "Training loss:0.586\n",
      "Training loss:0.593\n",
      "Training loss:0.555\n",
      "Training loss:0.426\n",
      "Validation loss:0.582\taccuracy:0.693\n",
      "\n",
      "\n",
      "====== epoch 67 ======\n",
      "Training loss:0.647\n",
      "Training loss:0.504\n",
      "Training loss:0.578\n",
      "Training loss:0.571\n",
      "Training loss:0.643\n",
      "Training loss:0.596\n",
      "Training loss:0.610\n",
      "Training loss:0.575\n",
      "Training loss:0.559\n",
      "Training loss:0.558\n",
      "Training loss:0.575\n",
      "Training loss:0.561\n",
      "Training loss:0.580\n",
      "Training loss:0.566\n",
      "Training loss:0.529\n",
      "Training loss:0.578\n",
      "Training loss:0.543\n",
      "Training loss:0.594\n",
      "Training loss:0.559\n",
      "Training loss:0.551\n",
      "Training loss:0.525\n",
      "Training loss:0.501\n",
      "Training loss:0.554\n",
      "Training loss:0.531\n",
      "Training loss:0.611\n",
      "Training loss:0.559\n",
      "Validation loss:0.605\taccuracy:0.693\n",
      "\n",
      "\n",
      "====== epoch 68 ======\n",
      "Training loss:0.562\n",
      "Training loss:0.510\n",
      "Training loss:0.524\n",
      "Training loss:0.606\n",
      "Training loss:0.594\n",
      "Training loss:0.537\n",
      "Training loss:0.582\n",
      "Training loss:0.588\n",
      "Training loss:0.621\n",
      "Training loss:0.546\n",
      "Training loss:0.528\n",
      "Training loss:0.598\n",
      "Training loss:0.593\n",
      "Training loss:0.546\n",
      "Training loss:0.632\n",
      "Training loss:0.549\n",
      "Training loss:0.633\n",
      "Training loss:0.563\n",
      "Training loss:0.597\n",
      "Training loss:0.548\n",
      "Training loss:0.576\n",
      "Training loss:0.564\n",
      "Training loss:0.555\n",
      "Training loss:0.573\n",
      "Training loss:0.605\n",
      "Training loss:0.536\n",
      "Validation loss:0.599\taccuracy:0.698\n",
      "\n",
      "\n",
      "====== epoch 69 ======\n",
      "Training loss:0.592\n",
      "Training loss:0.557\n",
      "Training loss:0.531\n",
      "Training loss:0.485\n",
      "Training loss:0.556\n",
      "Training loss:0.627\n",
      "Training loss:0.528\n",
      "Training loss:0.582\n",
      "Training loss:0.655\n",
      "Training loss:0.573\n",
      "Training loss:0.516\n",
      "Training loss:0.601\n",
      "Training loss:0.557\n",
      "Training loss:0.553\n",
      "Training loss:0.513\n",
      "Training loss:0.538\n",
      "Training loss:0.665\n",
      "Training loss:0.516\n",
      "Training loss:0.498\n",
      "Training loss:0.571\n",
      "Training loss:0.539\n",
      "Training loss:0.615\n",
      "Training loss:0.595\n",
      "Training loss:0.583\n",
      "Training loss:0.536\n",
      "Training loss:0.649\n",
      "Validation loss:0.590\taccuracy:0.701\n",
      "\n",
      "\n",
      "====== epoch 70 ======\n",
      "Training loss:0.574\n",
      "Training loss:0.589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.598\n",
      "Training loss:0.524\n",
      "Training loss:0.565\n",
      "Training loss:0.518\n",
      "Training loss:0.572\n",
      "Training loss:0.615\n",
      "Training loss:0.514\n",
      "Training loss:0.531\n",
      "Training loss:0.569\n",
      "Training loss:0.577\n",
      "Training loss:0.587\n",
      "Training loss:0.511\n",
      "Training loss:0.540\n",
      "Training loss:0.580\n",
      "Training loss:0.612\n",
      "Training loss:0.573\n",
      "Training loss:0.608\n",
      "Training loss:0.555\n",
      "Training loss:0.519\n",
      "Training loss:0.640\n",
      "Training loss:0.535\n",
      "Training loss:0.583\n",
      "Training loss:0.553\n",
      "Training loss:0.597\n",
      "Validation loss:0.587\taccuracy:0.713\n",
      "\n",
      "\n",
      "====== epoch 71 ======\n",
      "Training loss:0.573\n",
      "Training loss:0.618\n",
      "Training loss:0.593\n",
      "Training loss:0.541\n",
      "Training loss:0.609\n",
      "Training loss:0.560\n",
      "Training loss:0.555\n",
      "Training loss:0.588\n",
      "Training loss:0.569\n",
      "Training loss:0.508\n",
      "Training loss:0.570\n",
      "Training loss:0.573\n",
      "Training loss:0.625\n",
      "Training loss:0.607\n",
      "Training loss:0.554\n",
      "Training loss:0.516\n",
      "Training loss:0.607\n",
      "Training loss:0.509\n",
      "Training loss:0.545\n",
      "Training loss:0.538\n",
      "Training loss:0.525\n",
      "Training loss:0.592\n",
      "Training loss:0.609\n",
      "Training loss:0.584\n",
      "Training loss:0.560\n",
      "Training loss:0.529\n",
      "Validation loss:0.589\taccuracy:0.701\n",
      "\n",
      "\n",
      "====== epoch 72 ======\n",
      "Training loss:0.541\n",
      "Training loss:0.575\n",
      "Training loss:0.542\n",
      "Training loss:0.579\n",
      "Training loss:0.583\n",
      "Training loss:0.602\n",
      "Training loss:0.522\n",
      "Training loss:0.477\n",
      "Training loss:0.576\n",
      "Training loss:0.554\n",
      "Training loss:0.584\n",
      "Training loss:0.562\n",
      "Training loss:0.558\n",
      "Training loss:0.607\n",
      "Training loss:0.573\n",
      "Training loss:0.540\n",
      "Training loss:0.624\n",
      "Training loss:0.537\n",
      "Training loss:0.586\n",
      "Training loss:0.524\n",
      "Training loss:0.570\n",
      "Training loss:0.634\n",
      "Training loss:0.535\n",
      "Training loss:0.574\n",
      "Training loss:0.512\n",
      "Training loss:0.546\n",
      "Validation loss:0.598\taccuracy:0.706\n",
      "\n",
      "\n",
      "====== epoch 73 ======\n",
      "Training loss:0.572\n",
      "Training loss:0.521\n",
      "Training loss:0.565\n",
      "Training loss:0.586\n",
      "Training loss:0.569\n",
      "Training loss:0.579\n",
      "Training loss:0.563\n",
      "Training loss:0.582\n",
      "Training loss:0.593\n",
      "Training loss:0.585\n",
      "Training loss:0.574\n",
      "Training loss:0.629\n",
      "Training loss:0.566\n",
      "Training loss:0.555\n",
      "Training loss:0.568\n",
      "Training loss:0.538\n",
      "Training loss:0.662\n",
      "Training loss:0.531\n",
      "Training loss:0.559\n",
      "Training loss:0.537\n",
      "Training loss:0.559\n",
      "Training loss:0.547\n",
      "Training loss:0.506\n",
      "Training loss:0.601\n",
      "Training loss:0.541\n",
      "Training loss:0.588\n",
      "Validation loss:0.590\taccuracy:0.701\n",
      "\n",
      "\n",
      "====== epoch 74 ======\n",
      "Training loss:0.594\n",
      "Training loss:0.494\n",
      "Training loss:0.534\n",
      "Training loss:0.573\n",
      "Training loss:0.600\n",
      "Training loss:0.683\n",
      "Training loss:0.543\n",
      "Training loss:0.487\n",
      "Training loss:0.555\n",
      "Training loss:0.585\n",
      "Training loss:0.551\n",
      "Training loss:0.562\n",
      "Training loss:0.599\n",
      "Training loss:0.538\n",
      "Training loss:0.528\n",
      "Training loss:0.553\n",
      "Training loss:0.518\n",
      "Training loss:0.572\n",
      "Training loss:0.550\n",
      "Training loss:0.518\n",
      "Training loss:0.594\n",
      "Training loss:0.576\n",
      "Training loss:0.628\n",
      "Training loss:0.529\n",
      "Training loss:0.568\n",
      "Training loss:0.607\n",
      "Validation loss:0.592\taccuracy:0.693\n",
      "\n",
      "\n",
      "====== epoch 75 ======\n",
      "Training loss:0.608\n",
      "Training loss:0.580\n",
      "Training loss:0.507\n",
      "Training loss:0.582\n",
      "Training loss:0.532\n",
      "Training loss:0.519\n",
      "Training loss:0.633\n",
      "Training loss:0.523\n",
      "Training loss:0.573\n",
      "Training loss:0.545\n",
      "Training loss:0.502\n",
      "Training loss:0.579\n",
      "Training loss:0.622\n",
      "Training loss:0.676\n",
      "Training loss:0.626\n",
      "Training loss:0.536\n",
      "Training loss:0.550\n",
      "Training loss:0.612\n",
      "Training loss:0.591\n",
      "Training loss:0.572\n",
      "Training loss:0.584\n",
      "Training loss:0.522\n",
      "Training loss:0.542\n",
      "Training loss:0.550\n",
      "Training loss:0.542\n",
      "Training loss:0.628\n",
      "Validation loss:0.588\taccuracy:0.710\n",
      "\n",
      "\n",
      "====== epoch 76 ======\n",
      "Training loss:0.546\n",
      "Training loss:0.587\n",
      "Training loss:0.576\n",
      "Training loss:0.544\n",
      "Training loss:0.641\n",
      "Training loss:0.591\n",
      "Training loss:0.586\n",
      "Training loss:0.515\n",
      "Training loss:0.591\n",
      "Training loss:0.479\n",
      "Training loss:0.578\n",
      "Training loss:0.541\n",
      "Training loss:0.542\n",
      "Training loss:0.566\n",
      "Training loss:0.506\n",
      "Training loss:0.518\n",
      "Training loss:0.604\n",
      "Training loss:0.583\n",
      "Training loss:0.586\n",
      "Training loss:0.576\n",
      "Training loss:0.568\n",
      "Training loss:0.547\n",
      "Training loss:0.605\n",
      "Training loss:0.533\n",
      "Training loss:0.534\n",
      "Training loss:0.665\n",
      "Validation loss:0.596\taccuracy:0.701\n",
      "\n",
      "\n",
      "====== epoch 77 ======\n",
      "Training loss:0.550\n",
      "Training loss:0.628\n",
      "Training loss:0.589\n",
      "Training loss:0.482\n",
      "Training loss:0.545\n",
      "Training loss:0.557\n",
      "Training loss:0.564\n",
      "Training loss:0.596\n",
      "Training loss:0.540\n",
      "Training loss:0.527\n",
      "Training loss:0.591\n",
      "Training loss:0.568\n",
      "Training loss:0.548\n",
      "Training loss:0.534\n",
      "Training loss:0.552\n",
      "Training loss:0.497\n",
      "Training loss:0.587\n",
      "Training loss:0.637\n",
      "Training loss:0.597\n",
      "Training loss:0.514\n",
      "Training loss:0.551\n",
      "Training loss:0.631\n",
      "Training loss:0.573\n",
      "Training loss:0.537\n",
      "Training loss:0.535\n",
      "Training loss:0.498\n",
      "Validation loss:0.589\taccuracy:0.710\n",
      "\n",
      "\n",
      "====== epoch 78 ======\n",
      "Training loss:0.550\n",
      "Training loss:0.547\n",
      "Training loss:0.517\n",
      "Training loss:0.574\n",
      "Training loss:0.574\n",
      "Training loss:0.540\n",
      "Training loss:0.552\n",
      "Training loss:0.509\n",
      "Training loss:0.501\n",
      "Training loss:0.527\n",
      "Training loss:0.629\n",
      "Training loss:0.527\n",
      "Training loss:0.589\n",
      "Training loss:0.604\n",
      "Training loss:0.536\n",
      "Training loss:0.557\n",
      "Training loss:0.610\n",
      "Training loss:0.598\n",
      "Training loss:0.613\n",
      "Training loss:0.582\n",
      "Training loss:0.591\n",
      "Training loss:0.517\n",
      "Training loss:0.544\n",
      "Training loss:0.539\n",
      "Training loss:0.542\n",
      "Training loss:0.590\n",
      "Validation loss:0.588\taccuracy:0.708\n",
      "\n",
      "\n",
      "====== epoch 79 ======\n",
      "Training loss:0.522\n",
      "Training loss:0.557\n",
      "Training loss:0.598\n",
      "Training loss:0.593\n",
      "Training loss:0.529\n",
      "Training loss:0.550\n",
      "Training loss:0.615\n",
      "Training loss:0.504\n",
      "Training loss:0.559\n",
      "Training loss:0.530\n",
      "Training loss:0.590\n",
      "Training loss:0.543\n",
      "Training loss:0.649\n",
      "Training loss:0.527\n",
      "Training loss:0.568\n",
      "Training loss:0.519\n",
      "Training loss:0.593\n",
      "Training loss:0.557\n",
      "Training loss:0.542\n",
      "Training loss:0.497\n",
      "Training loss:0.498\n",
      "Training loss:0.582\n",
      "Training loss:0.607\n",
      "Training loss:0.591\n",
      "Training loss:0.557\n",
      "Training loss:0.610\n",
      "Validation loss:0.598\taccuracy:0.693\n",
      "\n",
      "\n",
      "====== epoch 80 ======\n",
      "Training loss:0.568\n",
      "Training loss:0.526\n",
      "Training loss:0.534\n",
      "Training loss:0.606\n",
      "Training loss:0.564\n",
      "Training loss:0.518\n",
      "Training loss:0.575\n",
      "Training loss:0.542\n",
      "Training loss:0.542\n",
      "Training loss:0.628\n",
      "Training loss:0.609\n",
      "Training loss:0.498\n",
      "Training loss:0.505\n",
      "Training loss:0.563\n",
      "Training loss:0.564\n",
      "Training loss:0.540\n",
      "Training loss:0.540\n",
      "Training loss:0.567\n",
      "Training loss:0.572\n",
      "Training loss:0.580\n",
      "Training loss:0.544\n",
      "Training loss:0.536\n",
      "Training loss:0.604\n",
      "Training loss:0.570\n",
      "Training loss:0.563\n",
      "Training loss:0.577\n",
      "Validation loss:0.587\taccuracy:0.703\n",
      "\n",
      "\n",
      "====== epoch 81 ======\n",
      "Training loss:0.606\n",
      "Training loss:0.478\n",
      "Training loss:0.603\n",
      "Training loss:0.519\n",
      "Training loss:0.519\n",
      "Training loss:0.497\n",
      "Training loss:0.606\n",
      "Training loss:0.537\n",
      "Training loss:0.507\n",
      "Training loss:0.624\n",
      "Training loss:0.623\n",
      "Training loss:0.533\n",
      "Training loss:0.596\n",
      "Training loss:0.589\n",
      "Training loss:0.542\n",
      "Training loss:0.559\n",
      "Training loss:0.568\n",
      "Training loss:0.546\n",
      "Training loss:0.587\n",
      "Training loss:0.484\n",
      "Training loss:0.542\n",
      "Training loss:0.531\n",
      "Training loss:0.572\n",
      "Training loss:0.474\n",
      "Training loss:0.584\n",
      "Training loss:0.567\n",
      "Validation loss:0.588\taccuracy:0.710\n",
      "\n",
      "\n",
      "====== epoch 82 ======\n",
      "Training loss:0.610\n",
      "Training loss:0.537\n",
      "Training loss:0.490\n",
      "Training loss:0.641\n",
      "Training loss:0.474\n",
      "Training loss:0.623\n",
      "Training loss:0.499\n",
      "Training loss:0.654\n",
      "Training loss:0.504\n",
      "Training loss:0.550\n",
      "Training loss:0.503\n",
      "Training loss:0.545\n",
      "Training loss:0.533\n",
      "Training loss:0.525\n",
      "Training loss:0.587\n",
      "Training loss:0.571\n",
      "Training loss:0.584\n",
      "Training loss:0.642\n",
      "Training loss:0.569\n",
      "Training loss:0.568\n",
      "Training loss:0.564\n",
      "Training loss:0.541\n",
      "Training loss:0.563\n",
      "Training loss:0.557\n",
      "Training loss:0.570\n",
      "Training loss:0.541\n",
      "Validation loss:0.591\taccuracy:0.701\n",
      "\n",
      "\n",
      "====== epoch 83 ======\n",
      "Training loss:0.510\n",
      "Training loss:0.564\n",
      "Training loss:0.596\n",
      "Training loss:0.598\n",
      "Training loss:0.497\n",
      "Training loss:0.569\n",
      "Training loss:0.489\n",
      "Training loss:0.600\n",
      "Training loss:0.542\n",
      "Training loss:0.572\n",
      "Training loss:0.572\n",
      "Training loss:0.546\n",
      "Training loss:0.534\n",
      "Training loss:0.582\n",
      "Training loss:0.491\n",
      "Training loss:0.560\n",
      "Training loss:0.499\n",
      "Training loss:0.586\n",
      "Training loss:0.595\n",
      "Training loss:0.500\n",
      "Training loss:0.530\n",
      "Training loss:0.601\n",
      "Training loss:0.666\n",
      "Training loss:0.503\n",
      "Training loss:0.565\n",
      "Training loss:0.637\n",
      "Validation loss:0.598\taccuracy:0.706\n",
      "\n",
      "\n",
      "====== epoch 84 ======\n",
      "Training loss:0.589\n",
      "Training loss:0.550\n",
      "Training loss:0.560\n",
      "Training loss:0.526\n",
      "Training loss:0.549\n",
      "Training loss:0.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.612\n",
      "Training loss:0.576\n",
      "Training loss:0.540\n",
      "Training loss:0.532\n",
      "Training loss:0.544\n",
      "Training loss:0.521\n",
      "Training loss:0.524\n",
      "Training loss:0.566\n",
      "Training loss:0.561\n",
      "Training loss:0.521\n",
      "Training loss:0.552\n",
      "Training loss:0.505\n",
      "Training loss:0.550\n",
      "Training loss:0.522\n",
      "Training loss:0.565\n",
      "Training loss:0.572\n",
      "Training loss:0.557\n",
      "Training loss:0.574\n",
      "Training loss:0.575\n",
      "Training loss:0.601\n",
      "Validation loss:0.594\taccuracy:0.703\n",
      "\n",
      "\n",
      "====== epoch 85 ======\n",
      "Training loss:0.583\n",
      "Training loss:0.474\n",
      "Training loss:0.552\n",
      "Training loss:0.536\n",
      "Training loss:0.600\n",
      "Training loss:0.566\n",
      "Training loss:0.612\n",
      "Training loss:0.506\n",
      "Training loss:0.568\n",
      "Training loss:0.557\n",
      "Training loss:0.532\n",
      "Training loss:0.569\n",
      "Training loss:0.502\n",
      "Training loss:0.591\n",
      "Training loss:0.539\n",
      "Training loss:0.572\n",
      "Training loss:0.455\n",
      "Training loss:0.565\n",
      "Training loss:0.630\n",
      "Training loss:0.550\n",
      "Training loss:0.552\n",
      "Training loss:0.657\n",
      "Training loss:0.605\n",
      "Training loss:0.539\n",
      "Training loss:0.520\n",
      "Training loss:0.572\n",
      "Validation loss:0.603\taccuracy:0.698\n",
      "\n",
      "\n",
      "====== epoch 86 ======\n",
      "Training loss:0.593\n",
      "Training loss:0.545\n",
      "Training loss:0.518\n",
      "Training loss:0.599\n",
      "Training loss:0.525\n",
      "Training loss:0.493\n",
      "Training loss:0.618\n",
      "Training loss:0.550\n",
      "Training loss:0.559\n",
      "Training loss:0.619\n",
      "Training loss:0.526\n",
      "Training loss:0.621\n",
      "Training loss:0.610\n",
      "Training loss:0.516\n",
      "Training loss:0.531\n",
      "Training loss:0.511\n",
      "Training loss:0.485\n",
      "Training loss:0.554\n",
      "Training loss:0.555\n",
      "Training loss:0.559\n",
      "Training loss:0.556\n",
      "Training loss:0.582\n",
      "Training loss:0.526\n",
      "Training loss:0.541\n",
      "Training loss:0.579\n",
      "Training loss:0.566\n",
      "Validation loss:0.593\taccuracy:0.701\n",
      "\n",
      "\n",
      "====== epoch 87 ======\n",
      "Training loss:0.522\n",
      "Training loss:0.514\n",
      "Training loss:0.538\n",
      "Training loss:0.524\n",
      "Training loss:0.566\n",
      "Training loss:0.523\n",
      "Training loss:0.613\n",
      "Training loss:0.563\n",
      "Training loss:0.515\n",
      "Training loss:0.610\n",
      "Training loss:0.614\n",
      "Training loss:0.601\n",
      "Training loss:0.573\n",
      "Training loss:0.601\n",
      "Training loss:0.617\n",
      "Training loss:0.575\n",
      "Training loss:0.539\n",
      "Training loss:0.480\n",
      "Training loss:0.553\n",
      "Training loss:0.567\n",
      "Training loss:0.557\n",
      "Training loss:0.524\n",
      "Training loss:0.569\n",
      "Training loss:0.583\n",
      "Training loss:0.580\n",
      "Training loss:0.587\n",
      "Validation loss:0.590\taccuracy:0.701\n",
      "\n",
      "\n",
      "====== epoch 88 ======\n",
      "Training loss:0.559\n",
      "Training loss:0.553\n",
      "Training loss:0.571\n",
      "Training loss:0.547\n",
      "Training loss:0.496\n",
      "Training loss:0.562\n",
      "Training loss:0.517\n",
      "Training loss:0.592\n",
      "Training loss:0.534\n",
      "Training loss:0.567\n",
      "Training loss:0.528\n",
      "Training loss:0.579\n",
      "Training loss:0.544\n",
      "Training loss:0.535\n",
      "Training loss:0.559\n",
      "Training loss:0.518\n",
      "Training loss:0.583\n",
      "Training loss:0.511\n",
      "Training loss:0.586\n",
      "Training loss:0.591\n",
      "Training loss:0.620\n",
      "Training loss:0.607\n",
      "Training loss:0.499\n",
      "Training loss:0.519\n",
      "Training loss:0.563\n",
      "Training loss:0.494\n",
      "Validation loss:0.594\taccuracy:0.708\n",
      "\n",
      "\n",
      "====== epoch 89 ======\n",
      "Training loss:0.491\n",
      "Training loss:0.556\n",
      "Training loss:0.547\n",
      "Training loss:0.558\n",
      "Training loss:0.540\n",
      "Training loss:0.503\n",
      "Training loss:0.524\n",
      "Training loss:0.599\n",
      "Training loss:0.555\n",
      "Training loss:0.534\n",
      "Training loss:0.611\n",
      "Training loss:0.558\n",
      "Training loss:0.536\n",
      "Training loss:0.625\n",
      "Training loss:0.504\n",
      "Training loss:0.602\n",
      "Training loss:0.576\n",
      "Training loss:0.535\n",
      "Training loss:0.533\n",
      "Training loss:0.533\n",
      "Training loss:0.567\n",
      "Training loss:0.584\n",
      "Training loss:0.520\n",
      "Training loss:0.603\n",
      "Training loss:0.646\n",
      "Training loss:0.563\n",
      "Validation loss:0.590\taccuracy:0.708\n",
      "\n",
      "\n",
      "====== epoch 90 ======\n",
      "Training loss:0.547\n",
      "Training loss:0.617\n",
      "Training loss:0.542\n",
      "Training loss:0.531\n",
      "Training loss:0.553\n",
      "Training loss:0.509\n",
      "Training loss:0.581\n",
      "Training loss:0.515\n",
      "Training loss:0.586\n",
      "Training loss:0.542\n",
      "Training loss:0.569\n",
      "Training loss:0.519\n",
      "Training loss:0.558\n",
      "Training loss:0.599\n",
      "Training loss:0.556\n",
      "Training loss:0.496\n",
      "Training loss:0.579\n",
      "Training loss:0.541\n",
      "Training loss:0.497\n",
      "Training loss:0.524\n",
      "Training loss:0.545\n",
      "Training loss:0.594\n",
      "Training loss:0.565\n",
      "Training loss:0.592\n",
      "Training loss:0.575\n",
      "Training loss:0.518\n",
      "Validation loss:0.590\taccuracy:0.723\n",
      "\n",
      "\n",
      "====== epoch 91 ======\n",
      "Training loss:0.490\n",
      "Training loss:0.521\n",
      "Training loss:0.604\n",
      "Training loss:0.634\n",
      "Training loss:0.538\n",
      "Training loss:0.551\n",
      "Training loss:0.544\n",
      "Training loss:0.640\n",
      "Training loss:0.594\n",
      "Training loss:0.581\n",
      "Training loss:0.539\n",
      "Training loss:0.539\n",
      "Training loss:0.582\n",
      "Training loss:0.547\n",
      "Training loss:0.562\n",
      "Training loss:0.532\n",
      "Training loss:0.553\n",
      "Training loss:0.564\n",
      "Training loss:0.548\n",
      "Training loss:0.509\n",
      "Training loss:0.553\n",
      "Training loss:0.542\n",
      "Training loss:0.501\n",
      "Training loss:0.508\n",
      "Training loss:0.580\n",
      "Training loss:0.556\n",
      "Validation loss:0.593\taccuracy:0.708\n",
      "\n",
      "\n",
      "====== epoch 92 ======\n",
      "Training loss:0.557\n",
      "Training loss:0.542\n",
      "Training loss:0.520\n",
      "Training loss:0.504\n",
      "Training loss:0.569\n",
      "Training loss:0.481\n",
      "Training loss:0.581\n",
      "Training loss:0.541\n",
      "Training loss:0.601\n",
      "Training loss:0.555\n",
      "Training loss:0.549\n",
      "Training loss:0.487\n",
      "Training loss:0.578\n",
      "Training loss:0.633\n",
      "Training loss:0.590\n",
      "Training loss:0.516\n",
      "Training loss:0.509\n",
      "Training loss:0.589\n",
      "Training loss:0.597\n",
      "Training loss:0.588\n",
      "Training loss:0.586\n",
      "Training loss:0.492\n",
      "Training loss:0.582\n",
      "Training loss:0.567\n",
      "Training loss:0.539\n",
      "Training loss:0.444\n",
      "Validation loss:0.624\taccuracy:0.676\n",
      "\n",
      "\n",
      "====== epoch 93 ======\n",
      "Training loss:0.527\n",
      "Training loss:0.571\n",
      "Training loss:0.589\n",
      "Training loss:0.549\n",
      "Training loss:0.491\n",
      "Training loss:0.620\n",
      "Training loss:0.538\n",
      "Training loss:0.616\n",
      "Training loss:0.528\n",
      "Training loss:0.587\n",
      "Training loss:0.591\n",
      "Training loss:0.503\n",
      "Training loss:0.500\n",
      "Training loss:0.516\n",
      "Training loss:0.547\n",
      "Training loss:0.559\n",
      "Training loss:0.541\n",
      "Training loss:0.590\n",
      "Training loss:0.632\n",
      "Training loss:0.558\n",
      "Training loss:0.531\n",
      "Training loss:0.610\n",
      "Training loss:0.604\n",
      "Training loss:0.473\n",
      "Training loss:0.535\n",
      "Training loss:0.571\n",
      "Validation loss:0.604\taccuracy:0.693\n",
      "\n",
      "\n",
      "====== epoch 94 ======\n",
      "Training loss:0.570\n",
      "Training loss:0.590\n",
      "Training loss:0.484\n",
      "Training loss:0.614\n",
      "Training loss:0.528\n",
      "Training loss:0.520\n",
      "Training loss:0.532\n",
      "Training loss:0.585\n",
      "Training loss:0.512\n",
      "Training loss:0.539\n",
      "Training loss:0.561\n",
      "Training loss:0.538\n",
      "Training loss:0.534\n",
      "Training loss:0.565\n",
      "Training loss:0.609\n",
      "Training loss:0.541\n",
      "Training loss:0.542\n",
      "Training loss:0.579\n",
      "Training loss:0.567\n",
      "Training loss:0.571\n",
      "Training loss:0.534\n",
      "Training loss:0.499\n",
      "Training loss:0.580\n",
      "Training loss:0.578\n",
      "Training loss:0.554\n",
      "Training loss:0.500\n",
      "Validation loss:0.591\taccuracy:0.710\n",
      "\n",
      "\n",
      "====== epoch 95 ======\n",
      "Training loss:0.533\n",
      "Training loss:0.533\n",
      "Training loss:0.553\n",
      "Training loss:0.561\n",
      "Training loss:0.577\n",
      "Training loss:0.574\n",
      "Training loss:0.574\n",
      "Training loss:0.580\n",
      "Training loss:0.553\n",
      "Training loss:0.503\n",
      "Training loss:0.550\n",
      "Training loss:0.571\n",
      "Training loss:0.556\n",
      "Training loss:0.507\n",
      "Training loss:0.584\n",
      "Training loss:0.559\n",
      "Training loss:0.553\n",
      "Training loss:0.575\n",
      "Training loss:0.501\n",
      "Training loss:0.533\n",
      "Training loss:0.533\n",
      "Training loss:0.595\n",
      "Training loss:0.566\n",
      "Training loss:0.525\n",
      "Training loss:0.499\n",
      "Training loss:0.473\n",
      "Validation loss:0.599\taccuracy:0.698\n",
      "\n",
      "\n",
      "====== epoch 96 ======\n",
      "Training loss:0.567\n",
      "Training loss:0.516\n",
      "Training loss:0.571\n",
      "Training loss:0.537\n",
      "Training loss:0.596\n",
      "Training loss:0.529\n",
      "Training loss:0.541\n",
      "Training loss:0.518\n",
      "Training loss:0.530\n",
      "Training loss:0.559\n",
      "Training loss:0.495\n",
      "Training loss:0.582\n",
      "Training loss:0.602\n",
      "Training loss:0.526\n",
      "Training loss:0.516\n",
      "Training loss:0.555\n",
      "Training loss:0.512\n",
      "Training loss:0.579\n",
      "Training loss:0.534\n",
      "Training loss:0.521\n",
      "Training loss:0.520\n",
      "Training loss:0.599\n",
      "Training loss:0.619\n",
      "Training loss:0.655\n",
      "Training loss:0.555\n",
      "Training loss:0.606\n",
      "Validation loss:0.591\taccuracy:0.732\n",
      "\n",
      "\n",
      "====== epoch 97 ======\n",
      "Training loss:0.601\n",
      "Training loss:0.520\n",
      "Training loss:0.534\n",
      "Training loss:0.572\n",
      "Training loss:0.561\n",
      "Training loss:0.639\n",
      "Training loss:0.551\n",
      "Training loss:0.560\n",
      "Training loss:0.535\n",
      "Training loss:0.606\n",
      "Training loss:0.571\n",
      "Training loss:0.532\n",
      "Training loss:0.565\n",
      "Training loss:0.565\n",
      "Training loss:0.516\n",
      "Training loss:0.560\n",
      "Training loss:0.544\n",
      "Training loss:0.531\n",
      "Training loss:0.492\n",
      "Training loss:0.550\n",
      "Training loss:0.566\n",
      "Training loss:0.571\n",
      "Training loss:0.554\n",
      "Training loss:0.547\n",
      "Training loss:0.524\n",
      "Training loss:0.518\n",
      "Validation loss:0.596\taccuracy:0.703\n",
      "\n",
      "\n",
      "====== epoch 98 ======\n",
      "Training loss:0.555\n",
      "Training loss:0.516\n",
      "Training loss:0.614\n",
      "Training loss:0.564\n",
      "Training loss:0.580\n",
      "Training loss:0.611\n",
      "Training loss:0.582\n",
      "Training loss:0.459\n",
      "Training loss:0.487\n",
      "Training loss:0.491\n",
      "Training loss:0.545\n",
      "Training loss:0.564\n",
      "Training loss:0.545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.593\n",
      "Training loss:0.525\n",
      "Training loss:0.442\n",
      "Training loss:0.588\n",
      "Training loss:0.567\n",
      "Training loss:0.625\n",
      "Training loss:0.578\n",
      "Training loss:0.555\n",
      "Training loss:0.621\n",
      "Training loss:0.481\n",
      "Training loss:0.504\n",
      "Training loss:0.563\n",
      "Training loss:0.563\n",
      "Validation loss:0.600\taccuracy:0.698\n",
      "\n",
      "\n",
      "====== epoch 99 ======\n",
      "Training loss:0.603\n",
      "Training loss:0.539\n",
      "Training loss:0.522\n",
      "Training loss:0.523\n",
      "Training loss:0.544\n",
      "Training loss:0.578\n",
      "Training loss:0.559\n",
      "Training loss:0.576\n",
      "Training loss:0.523\n",
      "Training loss:0.544\n",
      "Training loss:0.578\n",
      "Training loss:0.600\n",
      "Training loss:0.461\n",
      "Training loss:0.513\n",
      "Training loss:0.630\n",
      "Training loss:0.575\n",
      "Training loss:0.523\n",
      "Training loss:0.519\n",
      "Training loss:0.562\n",
      "Training loss:0.489\n",
      "Training loss:0.547\n",
      "Training loss:0.557\n",
      "Training loss:0.563\n",
      "Training loss:0.485\n",
      "Training loss:0.612\n",
      "Training loss:0.553\n",
      "Validation loss:0.597\taccuracy:0.708\n",
      "\n",
      "\n",
      "====== epoch 100 ======\n",
      "Training loss:0.546\n",
      "Training loss:0.534\n",
      "Training loss:0.452\n",
      "Training loss:0.538\n",
      "Training loss:0.616\n",
      "Training loss:0.526\n",
      "Training loss:0.626\n",
      "Training loss:0.508\n",
      "Training loss:0.530\n",
      "Training loss:0.524\n",
      "Training loss:0.538\n",
      "Training loss:0.555\n",
      "Training loss:0.581\n",
      "Training loss:0.541\n",
      "Training loss:0.508\n",
      "Training loss:0.537\n",
      "Training loss:0.527\n",
      "Training loss:0.562\n",
      "Training loss:0.565\n",
      "Training loss:0.523\n",
      "Training loss:0.524\n",
      "Training loss:0.515\n",
      "Training loss:0.551\n",
      "Training loss:0.587\n",
      "Training loss:0.519\n",
      "Training loss:0.544\n",
      "Validation loss:0.593\taccuracy:0.710\n",
      "\n",
      "\n",
      "====== epoch 101 ======\n",
      "Training loss:0.573\n",
      "Training loss:0.521\n",
      "Training loss:0.572\n",
      "Training loss:0.569\n",
      "Training loss:0.509\n",
      "Training loss:0.520\n",
      "Training loss:0.507\n",
      "Training loss:0.533\n",
      "Training loss:0.583\n",
      "Training loss:0.588\n",
      "Training loss:0.547\n",
      "Training loss:0.601\n",
      "Training loss:0.547\n",
      "Training loss:0.590\n",
      "Training loss:0.519\n",
      "Training loss:0.575\n",
      "Training loss:0.498\n",
      "Training loss:0.537\n",
      "Training loss:0.548\n",
      "Training loss:0.498\n",
      "Training loss:0.552\n",
      "Training loss:0.518\n",
      "Training loss:0.539\n",
      "Training loss:0.535\n",
      "Training loss:0.560\n",
      "Training loss:0.516\n",
      "Validation loss:0.597\taccuracy:0.706\n",
      "\n",
      "\n",
      "====== epoch 102 ======\n",
      "Training loss:0.535\n",
      "Training loss:0.510\n",
      "Training loss:0.551\n",
      "Training loss:0.572\n",
      "Training loss:0.535\n",
      "Training loss:0.528\n",
      "Training loss:0.563\n",
      "Training loss:0.563\n",
      "Training loss:0.581\n",
      "Training loss:0.492\n",
      "Training loss:0.498\n",
      "Training loss:0.524\n",
      "Training loss:0.636\n",
      "Training loss:0.546\n",
      "Training loss:0.628\n",
      "Training loss:0.490\n",
      "Training loss:0.594\n",
      "Training loss:0.533\n",
      "Training loss:0.511\n",
      "Training loss:0.544\n",
      "Training loss:0.521\n",
      "Training loss:0.603\n",
      "Training loss:0.490\n",
      "Training loss:0.549\n",
      "Training loss:0.598\n",
      "Training loss:0.539\n",
      "Validation loss:0.592\taccuracy:0.703\n",
      "\n",
      "\n",
      "====== epoch 103 ======\n",
      "Training loss:0.525\n",
      "Training loss:0.559\n",
      "Training loss:0.545\n",
      "Training loss:0.557\n",
      "Training loss:0.555\n",
      "Training loss:0.581\n",
      "Training loss:0.521\n",
      "Training loss:0.579\n",
      "Training loss:0.504\n",
      "Training loss:0.595\n",
      "Training loss:0.605\n",
      "Training loss:0.499\n",
      "Training loss:0.461\n",
      "Training loss:0.564\n",
      "Training loss:0.569\n",
      "Training loss:0.543\n",
      "Training loss:0.519\n",
      "Training loss:0.523\n",
      "Training loss:0.515\n",
      "Training loss:0.580\n",
      "Training loss:0.530\n",
      "Training loss:0.483\n",
      "Training loss:0.529\n",
      "Training loss:0.566\n",
      "Training loss:0.494\n",
      "Training loss:0.615\n",
      "Validation loss:0.614\taccuracy:0.693\n",
      "\n",
      "\n",
      "====== epoch 104 ======\n",
      "Training loss:0.575\n",
      "Training loss:0.614\n",
      "Training loss:0.470\n",
      "Training loss:0.559\n",
      "Training loss:0.534\n",
      "Training loss:0.567\n",
      "Training loss:0.582\n",
      "Training loss:0.582\n",
      "Training loss:0.567\n",
      "Training loss:0.601\n",
      "Training loss:0.571\n",
      "Training loss:0.519\n",
      "Training loss:0.499\n",
      "Training loss:0.536\n",
      "Training loss:0.611\n",
      "Training loss:0.554\n",
      "Training loss:0.533\n",
      "Training loss:0.551\n",
      "Training loss:0.531\n",
      "Training loss:0.531\n",
      "Training loss:0.492\n",
      "Training loss:0.527\n",
      "Training loss:0.533\n",
      "Training loss:0.541\n",
      "Training loss:0.532\n",
      "Training loss:0.493\n",
      "Validation loss:0.595\taccuracy:0.708\n",
      "\n",
      "\n",
      "====== epoch 105 ======\n",
      "Training loss:0.485\n",
      "Training loss:0.562\n",
      "Training loss:0.533\n",
      "Training loss:0.601\n",
      "Training loss:0.576\n",
      "Training loss:0.519\n",
      "Training loss:0.613\n",
      "Training loss:0.496\n",
      "Training loss:0.536\n",
      "Training loss:0.522\n",
      "Training loss:0.528\n",
      "Training loss:0.607\n",
      "Training loss:0.644\n",
      "Training loss:0.572\n",
      "Training loss:0.488\n",
      "Training loss:0.600\n",
      "Training loss:0.513\n",
      "Training loss:0.506\n",
      "Training loss:0.561\n",
      "Training loss:0.579\n",
      "Training loss:0.565\n",
      "Training loss:0.491\n",
      "Training loss:0.528\n",
      "Training loss:0.481\n",
      "Training loss:0.561\n",
      "Training loss:0.490\n",
      "Validation loss:0.592\taccuracy:0.703\n",
      "\n",
      "\n",
      "====== epoch 106 ======\n",
      "Training loss:0.569\n",
      "Training loss:0.573\n",
      "Training loss:0.503\n",
      "Training loss:0.548\n",
      "Training loss:0.497\n",
      "Training loss:0.545\n",
      "Training loss:0.529\n",
      "Training loss:0.569\n",
      "Training loss:0.502\n",
      "Training loss:0.514\n",
      "Training loss:0.541\n",
      "Training loss:0.573\n",
      "Training loss:0.569\n",
      "Training loss:0.583\n",
      "Training loss:0.544\n",
      "Training loss:0.685\n",
      "Training loss:0.510\n",
      "Training loss:0.589\n",
      "Training loss:0.509\n",
      "Training loss:0.510\n",
      "Training loss:0.585\n",
      "Training loss:0.540\n",
      "Training loss:0.555\n",
      "Training loss:0.589\n",
      "Training loss:0.521\n",
      "Training loss:0.564\n",
      "Validation loss:0.596\taccuracy:0.708\n",
      "\n",
      "\n",
      "====== epoch 107 ======\n",
      "Training loss:0.562\n",
      "Training loss:0.507\n",
      "Training loss:0.562\n",
      "Training loss:0.564\n",
      "Training loss:0.512\n",
      "Training loss:0.531\n",
      "Training loss:0.494\n",
      "Training loss:0.530\n",
      "Training loss:0.551\n",
      "Training loss:0.568\n",
      "Training loss:0.493\n",
      "Training loss:0.545\n",
      "Training loss:0.620\n",
      "Training loss:0.524\n",
      "Training loss:0.523\n",
      "Training loss:0.521\n",
      "Training loss:0.552\n",
      "Training loss:0.580\n",
      "Training loss:0.638\n",
      "Training loss:0.534\n",
      "Training loss:0.550\n",
      "Training loss:0.500\n",
      "Training loss:0.524\n",
      "Training loss:0.564\n",
      "Training loss:0.557\n",
      "Training loss:0.515\n",
      "Validation loss:0.601\taccuracy:0.701\n",
      "\n",
      "\n",
      "====== epoch 108 ======\n",
      "Training loss:0.543\n",
      "Training loss:0.468\n",
      "Training loss:0.529\n",
      "Training loss:0.477\n",
      "Training loss:0.522\n",
      "Training loss:0.516\n",
      "Training loss:0.604\n",
      "Training loss:0.563\n",
      "Training loss:0.598\n",
      "Training loss:0.604\n",
      "Training loss:0.588\n",
      "Training loss:0.478\n",
      "Training loss:0.535\n",
      "Training loss:0.543\n",
      "Training loss:0.536\n",
      "Training loss:0.557\n",
      "Training loss:0.493\n",
      "Training loss:0.522\n",
      "Training loss:0.616\n",
      "Training loss:0.526\n",
      "Training loss:0.557\n",
      "Training loss:0.555\n",
      "Training loss:0.495\n",
      "Training loss:0.451\n",
      "Training loss:0.526\n",
      "Training loss:0.612\n",
      "Validation loss:0.599\taccuracy:0.701\n",
      "\n",
      "\n",
      "====== epoch 109 ======\n",
      "Training loss:0.518\n",
      "Training loss:0.532\n",
      "Training loss:0.514\n",
      "Training loss:0.576\n",
      "Training loss:0.480\n",
      "Training loss:0.636\n",
      "Training loss:0.610\n",
      "Training loss:0.584\n",
      "Training loss:0.507\n",
      "Training loss:0.506\n",
      "Training loss:0.522\n",
      "Training loss:0.557\n",
      "Training loss:0.569\n",
      "Training loss:0.524\n",
      "Training loss:0.552\n",
      "Training loss:0.507\n",
      "Training loss:0.549\n",
      "Training loss:0.507\n",
      "Training loss:0.603\n",
      "Training loss:0.512\n",
      "Training loss:0.607\n",
      "Training loss:0.542\n",
      "Training loss:0.502\n",
      "Training loss:0.477\n",
      "Training loss:0.569\n",
      "Training loss:0.525\n",
      "Validation loss:0.601\taccuracy:0.703\n",
      "\n",
      "\n",
      "====== epoch 110 ======\n",
      "Training loss:0.513\n",
      "Training loss:0.543\n",
      "Training loss:0.544\n",
      "Training loss:0.536\n",
      "Training loss:0.554\n",
      "Training loss:0.533\n",
      "Training loss:0.566\n",
      "Training loss:0.492\n",
      "Training loss:0.536\n",
      "Training loss:0.622\n",
      "Training loss:0.509\n",
      "Training loss:0.485\n",
      "Training loss:0.652\n",
      "Training loss:0.520\n",
      "Training loss:0.517\n",
      "Training loss:0.575\n",
      "Training loss:0.566\n",
      "Training loss:0.531\n",
      "Training loss:0.564\n",
      "Training loss:0.531\n",
      "Training loss:0.526\n",
      "Training loss:0.561\n",
      "Training loss:0.492\n",
      "Training loss:0.525\n",
      "Training loss:0.600\n",
      "Training loss:0.595\n",
      "Validation loss:0.594\taccuracy:0.708\n",
      "\n",
      "\n",
      "====== epoch 111 ======\n",
      "Training loss:0.512\n",
      "Training loss:0.630\n",
      "Training loss:0.527\n",
      "Training loss:0.580\n",
      "Training loss:0.577\n",
      "Training loss:0.491\n",
      "Training loss:0.563\n",
      "Training loss:0.540\n",
      "Training loss:0.534\n",
      "Training loss:0.530\n",
      "Training loss:0.561\n",
      "Training loss:0.496\n",
      "Training loss:0.590\n",
      "Training loss:0.565\n",
      "Training loss:0.535\n",
      "Training loss:0.538\n",
      "Training loss:0.529\n",
      "Training loss:0.543\n",
      "Training loss:0.608\n",
      "Training loss:0.561\n",
      "Training loss:0.494\n",
      "Training loss:0.526\n",
      "Training loss:0.497\n",
      "Training loss:0.503\n",
      "Training loss:0.538\n",
      "Training loss:0.575\n",
      "Validation loss:0.612\taccuracy:0.701\n",
      "\n",
      "\n",
      "====== epoch 112 ======\n",
      "Training loss:0.514\n",
      "Training loss:0.540\n",
      "Training loss:0.621\n",
      "Training loss:0.576\n",
      "Training loss:0.567\n",
      "Training loss:0.553\n",
      "Training loss:0.451\n",
      "Training loss:0.516\n",
      "Training loss:0.548\n",
      "Training loss:0.548\n",
      "Training loss:0.518\n",
      "Training loss:0.579\n",
      "Training loss:0.540\n",
      "Training loss:0.573\n",
      "Training loss:0.550\n",
      "Training loss:0.502\n",
      "Training loss:0.476\n",
      "Training loss:0.552\n",
      "Training loss:0.536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:0.537\n",
      "Training loss:0.529\n",
      "Training loss:0.548\n",
      "Training loss:0.530\n",
      "Training loss:0.540\n",
      "Training loss:0.499\n",
      "Training loss:0.518\n",
      "Validation loss:0.600\taccuracy:0.708\n",
      "\n",
      "\n",
      "====== epoch 113 ======\n",
      "Training loss:0.549\n",
      "Training loss:0.462\n",
      "Training loss:0.519\n",
      "Training loss:0.585\n",
      "Training loss:0.553\n",
      "Training loss:0.534\n",
      "Training loss:0.486\n",
      "Training loss:0.574\n",
      "Training loss:0.528\n",
      "Training loss:0.560\n",
      "Training loss:0.420\n",
      "Training loss:0.558\n",
      "Training loss:0.538\n",
      "Training loss:0.662\n",
      "Training loss:0.545\n",
      "Training loss:0.505\n",
      "Training loss:0.585\n",
      "Training loss:0.511\n",
      "Training loss:0.500\n",
      "Training loss:0.521\n",
      "Training loss:0.449\n",
      "Training loss:0.568\n",
      "Training loss:0.587\n",
      "Training loss:0.526\n",
      "Training loss:0.561\n",
      "Training loss:0.557\n",
      "Validation loss:0.597\taccuracy:0.713\n",
      "\n",
      "\n",
      "====== epoch 114 ======\n",
      "Training loss:0.486\n",
      "Training loss:0.576\n",
      "Training loss:0.521\n",
      "Training loss:0.521\n",
      "Training loss:0.590\n",
      "Training loss:0.544\n",
      "Training loss:0.575\n",
      "Training loss:0.520\n",
      "Training loss:0.493\n",
      "Training loss:0.564\n",
      "Training loss:0.564\n",
      "Training loss:0.589\n",
      "Training loss:0.620\n",
      "Training loss:0.549\n",
      "Training loss:0.500\n",
      "Training loss:0.527\n",
      "Training loss:0.477\n",
      "Training loss:0.503\n",
      "Training loss:0.579\n",
      "Training loss:0.577\n",
      "Training loss:0.566\n",
      "Training loss:0.577\n",
      "Training loss:0.452\n",
      "Training loss:0.572\n",
      "Training loss:0.536\n",
      "Training loss:0.531\n",
      "Validation loss:0.603\taccuracy:0.706\n",
      "\n",
      "\n",
      "====== epoch 115 ======\n",
      "Training loss:0.529\n",
      "Training loss:0.547\n",
      "Training loss:0.567\n",
      "Training loss:0.488\n",
      "Training loss:0.527\n",
      "Training loss:0.508\n",
      "Training loss:0.473\n",
      "Training loss:0.496\n",
      "Training loss:0.549\n",
      "Training loss:0.566\n",
      "Training loss:0.530\n",
      "Training loss:0.518\n",
      "Training loss:0.588\n",
      "Training loss:0.564\n",
      "Training loss:0.557\n",
      "Training loss:0.547\n",
      "Training loss:0.551\n",
      "Training loss:0.565\n",
      "Training loss:0.591\n",
      "Training loss:0.539\n",
      "Training loss:0.466\n",
      "Training loss:0.571\n",
      "Training loss:0.524\n",
      "Training loss:0.491\n",
      "Training loss:0.647\n",
      "Training loss:0.555\n",
      "Validation loss:0.599\taccuracy:0.708\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'fotmat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b090ddc5b6b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'latest.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuarcy:{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfotmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'fotmat'"
     ]
    }
   ],
   "source": [
    "# data loader & model setup\n",
    "train_loader = DataLoader(training_set, batch_size=args.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(validation_set,batch_size=args.batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set,batch_size=1, shuffle=False)\n",
    "model = Net(args).to(args.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "def test(model,loader):\n",
    "    model.eval()\n",
    "    correct = 0.\n",
    "    loss = 0.\n",
    "    for data in loader:\n",
    "        data = data.to(args.device)\n",
    "        out = model(data)\n",
    "        pred = out.max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        loss += F.nll_loss(out,data.y,reduction='sum').item()\n",
    "    return correct / len(loader.dataset),loss / len(loader.dataset)\n",
    "\n",
    "min_loss = 1e10\n",
    "patience = 0\n",
    "val_loss_plot = []\n",
    "val_acc_plot = []\n",
    "args.epochs = 150\n",
    "for epoch in range(args.epochs):\n",
    "    print(\"\\n\")\n",
    "    print(\"====== epoch {} ======\".format(epoch))\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(args.device)\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        print(\"Training loss:{:.3f}\".format(loss.item()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    val_acc,val_loss = test(model,val_loader)\n",
    "    print(\"Validation loss:{:.3f}\\taccuracy:{:.3f}\".format(val_loss,val_acc))\n",
    "    if val_loss < min_loss:\n",
    "        torch.save(model.state_dict(),'latest.pth')\n",
    "        print(\"Model saved at epoch{}\".format(epoch))\n",
    "        min_loss = val_loss\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "    if patience > args.patience:\n",
    "        break \n",
    "    val_loss_plot.append(val_loss)\n",
    "    val_acc_plot.append(val_acc)\n",
    "\n",
    "model = Net(args).to(args.device)\n",
    "model.load_state_dict(torch.load('latest.pth'))\n",
    "test_acc,test_loss = test(model,test_loader)\n",
    "print(\"Test accuarcy:{}\".fotmat(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ywkim/pytorch_geometric/venv/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "num_xaxis = 115 #args.epochs\n",
    "fig, ax1 = plt.subplots()\n",
    "x_axis = np.linspace(1,num_xaxis,num=num_xaxis)\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epochs',fontsize=15)\n",
    "ax1.set_ylabel('val_loss', color=color,fontsize=15)\n",
    "ax1.plot(x_axis, val_loss_plot, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('val_acc', color=color,fontsize=15) \n",
    "ax2.plot(x_axis, val_acc_plot, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax1.set_title('SAGP-'+str(args.dataset),fontsize=15)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()\n",
    "fig.savefig('./GNN_'+str(args.dataset)+'_'+str(epoch)+'.pdf',dpi=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
